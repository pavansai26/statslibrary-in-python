{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4,suppress=True)\n",
    "#pd.set_printoptions(notebook_repr_html=False,\n",
    "                   #precision=4,\n",
    "                   #max_columns=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols,rlm,glm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.regression models in statsmodels.regression\n",
    "2.discrete choice models in statsmodels.discrete\n",
    "3.robust linear models in statsmodels.robust\n",
    "4.generalized linear models in statsmodels.genmod\n",
    "5.timeseries analysis in statsmodels.tsa\n",
    "6.nonparametric models in statsmodels.nonparametric\n",
    "7.plotting functions in statsmodels.graphics\n",
    "8.input/output in statsmodels.iolib(foreign data,ascii,html,latex tables)\n",
    "9.statistical tests,anova in statsmodels.stats\n",
    "10.data sets in statsmodels.datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.base import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module statsmodels.base.model in statsmodels.base:\n",
      "\n",
      "NAME\n",
      "    statsmodels.base.model\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        Model\n",
      "            LikelihoodModel\n",
      "                GenericLikelihoodModel\n",
      "        ResultMixin\n",
      "        Results\n",
      "            LikelihoodModelResults\n",
      "                GenericLikelihoodModelResults(LikelihoodModelResults, ResultMixin)\n",
      "    statsmodels.base.wrapper.ResultsWrapper(builtins.object)\n",
      "        LikelihoodResultsWrapper\n",
      "    \n",
      "    class GenericLikelihoodModel(LikelihoodModel)\n",
      "     |  GenericLikelihoodModel(endog, exog=None, loglike=None, score=None, hessian=None, missing='none', extra_params_names=None, **kwds)\n",
      "     |  \n",
      "     |  Allows the fitting of any likelihood function via maximum likelihood.\n",
      "     |  \n",
      "     |  A subclass needs to specify at least the log-likelihood\n",
      "     |  If the log-likelihood is specified for each observation, then results that\n",
      "     |  require the Jacobian will be available. (The other case is not tested yet.)\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  Optimization methods that require only a likelihood function are 'nm' and\n",
      "     |  'powell'\n",
      "     |  \n",
      "     |  Optimization methods that require a likelihood function and a\n",
      "     |  score/gradient are 'bfgs', 'cg', and 'ncg'. A function to compute the\n",
      "     |  Hessian is optional for 'ncg'.\n",
      "     |  \n",
      "     |  Optimization method that require a likelihood function, a score/gradient,\n",
      "     |  and a Hessian is 'newton'\n",
      "     |  \n",
      "     |  If they are not overwritten by a subclass, then numerical gradient,\n",
      "     |  Jacobian and Hessian of the log-likelihood are caclulated by numerical\n",
      "     |  forward differentiation. This might results in some cases in precision\n",
      "     |  problems, and the Hessian might not be positive definite. Even if the\n",
      "     |  Hessian is not positive definite the covariance matrix of the parameter\n",
      "     |  estimates based on the outer product of the Jacobian might still be valid.\n",
      "     |  \n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  see also subclasses in directory miscmodels\n",
      "     |  \n",
      "     |  import statsmodels.api as sm\n",
      "     |  data = sm.datasets.spector.load()\n",
      "     |  data.exog = sm.add_constant(data.exog)\n",
      "     |  # in this dir\n",
      "     |  from model import GenericLikelihoodModel\n",
      "     |  probit_mod = sm.Probit(data.endog, data.exog)\n",
      "     |  probit_res = probit_mod.fit()\n",
      "     |  loglike = probit_mod.loglike\n",
      "     |  score = probit_mod.score\n",
      "     |  mod = GenericLikelihoodModel(data.endog, data.exog, loglike, score)\n",
      "     |  res = mod.fit(method=\"nm\", maxiter = 500)\n",
      "     |  import numpy as np\n",
      "     |  np.allclose(res.params, probit_res.params)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GenericLikelihoodModel\n",
      "     |      LikelihoodModel\n",
      "     |      Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, exog=None, loglike=None, score=None, hessian=None, missing='none', extra_params_names=None, **kwds)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  expandparams(self, params)\n",
      "     |      expand to full parameter array when some parameters are fixed\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : array\n",
      "     |          reduced parameter array\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      paramsfull : array\n",
      "     |          expanded parameter array where fixed parameters are included\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Calling this requires that self.fixed_params and self.fixed_paramsmask\n",
      "     |      are defined.\n",
      "     |      \n",
      "     |      *developer notes:*\n",
      "     |      \n",
      "     |      This can be used in the log-likelihood to ...\n",
      "     |      \n",
      "     |      this could also be replaced by a more general parameter\n",
      "     |      transformation.\n",
      "     |  \n",
      "     |  fit(self, start_params=None, method='nm', maxiter=500, full_output=1, disp=1, callback=None, retall=0, **kwargs)\n",
      "     |      Fit the model using maximum likelihood.\n",
      "     |      \n",
      "     |      The rest of the docstring is from\n",
      "     |      statsmodels.LikelihoodModel.fit\n",
      "     |  \n",
      "     |  hessian(self, params)\n",
      "     |      Hessian of log-likelihood evaluated at params\n",
      "     |  \n",
      "     |  hessian_factor(self, params, scale=None, observed=True)\n",
      "     |      Weights for calculating Hessian\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params : ndarray\n",
      "     |          parameter at which Hessian is evaluated\n",
      "     |      scale : None or float\n",
      "     |          If scale is None, then the default scale will be calculated.\n",
      "     |          Default scale is defined by `self.scaletype` and set in fit.\n",
      "     |          If scale is not None, then it is used as a fixed scale.\n",
      "     |      observed : bool\n",
      "     |          If True, then the observed Hessian is returned. If false then the\n",
      "     |          expected information matrix is returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      hessian_factor : ndarray, 1d\n",
      "     |          A 1d weight vector used in the calculation of the Hessian.\n",
      "     |          The hessian is obtained by `(exog.T * hessian_factor).dot(exog)`\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize (possibly re-initialize) a Model instance. For\n",
      "     |      instance, the design matrix of a linear model may change\n",
      "     |      and some things must be recomputed.\n",
      "     |  \n",
      "     |  loglike(self, params)\n",
      "     |      Log-likelihood of model.\n",
      "     |  \n",
      "     |  loglikeobs(self, params)\n",
      "     |  \n",
      "     |  nloglike(self, params)\n",
      "     |  \n",
      "     |  reduceparams(self, params)\n",
      "     |  \n",
      "     |  score(self, params)\n",
      "     |      Gradient of log-likelihood evaluated at params\n",
      "     |  \n",
      "     |  score_obs(self, params, **kwds)\n",
      "     |      Jacobian/Gradient of log-likelihood evaluated at params for each\n",
      "     |      observation.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from LikelihoodModel:\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model\n",
      "     |      \n",
      "     |      Returns -Hessian of loglike evaluated at params.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Model:\n",
      "     |  \n",
      "     |  predict(self, params, exog=None, *args, **kwargs)\n",
      "     |      After a model has been fit predict returns the fitted values.\n",
      "     |      \n",
      "     |      This is a placeholder intended to be overwritten by individual models.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Model:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      "     |      Create a Model from a formula and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model\n",
      "     |      data : array-like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      subset : array-like\n",
      "     |          An array-like object of booleans, integers, or index values that\n",
      "     |          indicate the subset of df to use in the model. Assumes df is a\n",
      "     |          `pandas.DataFrame`\n",
      "     |      drop_cols : array-like\n",
      "     |          Columns to drop from the design matrix.  Cannot be used to\n",
      "     |          drop terms involving categoricals.\n",
      "     |      args : extra arguments\n",
      "     |          These are passed to the model\n",
      "     |      kwargs : extra keyword arguments\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model : Model instance\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      ------\n",
      "     |      data must define __getitem__ with the keys in the formula terms\n",
      "     |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      "     |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      Names of exogenous variables\n",
      "    \n",
      "    class GenericLikelihoodModelResults(LikelihoodModelResults, ResultMixin)\n",
      "     |  GenericLikelihoodModelResults(model, mlefit)\n",
      "     |  \n",
      "     |  A results class for the discrete dependent variable models.\n",
      "     |  \n",
      "     |  ..Warning :\n",
      "     |  \n",
      "     |  The following description has not been updated to this version/class.\n",
      "     |  Where are AIC, BIC, ....? docstring looks like copy from discretemod\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  model : A DiscreteModel instance\n",
      "     |  mlefit : instance of LikelihoodResults\n",
      "     |      This contains the numerical optimization results as returned by\n",
      "     |      LikelihoodModel.fit(), in a superclass of GnericLikelihoodModels\n",
      "     |  \n",
      "     |  \n",
      "     |  Returns\n",
      "     |  -------\n",
      "     |  *Attributes*\n",
      "     |  \n",
      "     |  Warning most of these are not available yet\n",
      "     |  \n",
      "     |  aic : float\n",
      "     |      Akaike information criterion.  -2*(`llf` - p) where p is the number\n",
      "     |      of regressors including the intercept.\n",
      "     |  bic : float\n",
      "     |      Bayesian information criterion. -2*`llf` + ln(`nobs`)*p where p is the\n",
      "     |      number of regressors including the intercept.\n",
      "     |  bse : array\n",
      "     |      The standard errors of the coefficients.\n",
      "     |  df_resid : float\n",
      "     |      See model definition.\n",
      "     |  df_model : float\n",
      "     |      See model definition.\n",
      "     |  fitted_values : array\n",
      "     |      Linear predictor XB.\n",
      "     |  llf : float\n",
      "     |      Value of the loglikelihood\n",
      "     |  llnull : float\n",
      "     |      Value of the constant-only loglikelihood\n",
      "     |  llr : float\n",
      "     |      Likelihood ratio chi-squared statistic; -2*(`llnull` - `llf`)\n",
      "     |  llr_pvalue : float\n",
      "     |      The chi-squared probability of getting a log-likelihood ratio\n",
      "     |      statistic greater than llr.  llr has a chi-squared distribution\n",
      "     |      with degrees of freedom `df_model`.\n",
      "     |  prsquared : float\n",
      "     |      McFadden's pseudo-R-squared. 1 - (`llf`/`llnull`)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GenericLikelihoodModelResults\n",
      "     |      LikelihoodModelResults\n",
      "     |      Results\n",
      "     |      ResultMixin\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, model, mlefit)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  summary(self, yname=None, xname=None, title=None, alpha=0.05)\n",
      "     |      Summarize the Regression Results\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      -----------\n",
      "     |      yname : string, optional\n",
      "     |          Default is `y`\n",
      "     |      xname : list of strings, optional\n",
      "     |          Default is `var_##` for ## in p the number of regressors\n",
      "     |      title : string, optional\n",
      "     |          Title for the top table. If not None, then this replaces the\n",
      "     |          default title\n",
      "     |      alpha : float\n",
      "     |          significance level for the confidence intervals\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      smry : Summary instance\n",
      "     |          this holds the summary tables and text, which can be printed or\n",
      "     |          converted to various output formats.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      statsmodels.iolib.summary.Summary : class to hold summary\n",
      "     |          results\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from LikelihoodModelResults:\n",
      "     |  \n",
      "     |  bse(self)\n",
      "     |  \n",
      "     |  conf_int(self, alpha=0.05, cols=None, method='default')\n",
      "     |      Returns the confidence interval of the fitted parameters.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      alpha : float, optional\n",
      "     |          The significance level for the confidence interval.\n",
      "     |          ie., The default `alpha` = .05 returns a 95% confidence interval.\n",
      "     |      cols : array-like, optional\n",
      "     |          `cols` specifies which confidence intervals to return\n",
      "     |      method : string\n",
      "     |          Not Implemented Yet\n",
      "     |          Method to estimate the confidence_interval.\n",
      "     |          \"Default\" : uses self.bse which is based on inverse Hessian for MLE\n",
      "     |          \"hjjh\" :\n",
      "     |          \"jac\" :\n",
      "     |          \"boot-bse\"\n",
      "     |          \"boot_quant\"\n",
      "     |          \"profile\"\n",
      "     |      \n",
      "     |      \n",
      "     |      Returns\n",
      "     |      --------\n",
      "     |      conf_int : array\n",
      "     |          Each row contains [lower, upper] limits of the confidence interval\n",
      "     |          for the corresponding parameter. The first column contains all\n",
      "     |          lower, the second column contains all upper limits.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import statsmodels.api as sm\n",
      "     |      >>> data = sm.datasets.longley.load()\n",
      "     |      >>> data.exog = sm.add_constant(data.exog)\n",
      "     |      >>> results = sm.OLS(data.endog, data.exog).fit()\n",
      "     |      >>> results.conf_int()\n",
      "     |      array([[-5496529.48322745, -1467987.78596704],\n",
      "     |             [    -177.02903529,      207.15277984],\n",
      "     |             [      -0.1115811 ,        0.03994274],\n",
      "     |             [      -3.12506664,       -0.91539297],\n",
      "     |             [      -1.5179487 ,       -0.54850503],\n",
      "     |             [      -0.56251721,        0.460309  ],\n",
      "     |             [     798.7875153 ,     2859.51541392]])\n",
      "     |      \n",
      "     |      \n",
      "     |      >>> results.conf_int(cols=(2,3))\n",
      "     |      array([[-0.1115811 ,  0.03994274],\n",
      "     |             [-3.12506664, -0.91539297]])\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The confidence interval is based on the standard normal distribution.\n",
      "     |      Models wish to use a different distribution should overwrite this\n",
      "     |      method.\n",
      "     |  \n",
      "     |  cov_params(self, r_matrix=None, column=None, scale=None, cov_p=None, other=None)\n",
      "     |      Returns the variance/covariance matrix.\n",
      "     |      \n",
      "     |      The variance/covariance matrix can be of a linear contrast\n",
      "     |      of the estimates of params or all params multiplied by scale which\n",
      "     |      will usually be an estimate of sigma^2.  Scale is assumed to be\n",
      "     |      a scalar.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      r_matrix : array-like\n",
      "     |          Can be 1d, or 2d.  Can be used alone or with other.\n",
      "     |      column :  array-like, optional\n",
      "     |          Must be used on its own.  Can be 0d or 1d see below.\n",
      "     |      scale : float, optional\n",
      "     |          Can be specified or not.  Default is None, which means that\n",
      "     |          the scale argument is taken from the model.\n",
      "     |      other : array-like, optional\n",
      "     |          Can be used when r_matrix is specified.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      cov : ndarray\n",
      "     |          covariance matrix of the parameter estimates or of linear\n",
      "     |          combination of parameter estimates. See Notes.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      (The below are assumed to be in matrix notation.)\n",
      "     |      \n",
      "     |      If no argument is specified returns the covariance matrix of a model\n",
      "     |      ``(scale)*(X.T X)^(-1)``\n",
      "     |      \n",
      "     |      If contrast is specified it pre and post-multiplies as follows\n",
      "     |      ``(scale) * r_matrix (X.T X)^(-1) r_matrix.T``\n",
      "     |      \n",
      "     |      If contrast and other are specified returns\n",
      "     |      ``(scale) * r_matrix (X.T X)^(-1) other.T``\n",
      "     |      \n",
      "     |      If column is specified returns\n",
      "     |      ``(scale) * (X.T X)^(-1)[column,column]`` if column is 0d\n",
      "     |      \n",
      "     |      OR\n",
      "     |      \n",
      "     |      ``(scale) * (X.T X)^(-1)[column][:,column]`` if column is 1d\n",
      "     |  \n",
      "     |  f_test(self, r_matrix, cov_p=None, scale=1.0, invcov=None)\n",
      "     |      Compute the F-test for a joint linear hypothesis.\n",
      "     |      \n",
      "     |      This is a special case of `wald_test` that always uses the F\n",
      "     |      distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      r_matrix : array-like, str, or tuple\n",
      "     |          - array : An r x k array where r is the number of restrictions to\n",
      "     |            test and k is the number of regressors. It is assumed\n",
      "     |            that the linear combination is equal to zero.\n",
      "     |          - str : The full hypotheses to test can be given as a string.\n",
      "     |            See the examples.\n",
      "     |          - tuple : A tuple of arrays in the form (R, q), ``q`` can be\n",
      "     |            either a scalar or a length k row vector.\n",
      "     |      cov_p : array-like, optional\n",
      "     |          An alternative estimate for the parameter covariance matrix.\n",
      "     |          If None is given, self.normalized_cov_params is used.\n",
      "     |      scale : float, optional\n",
      "     |          Default is 1.0 for no scaling.\n",
      "     |      invcov : array-like, optional\n",
      "     |          A q x q array to specify an inverse covariance matrix based on a\n",
      "     |          restrictions matrix.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      res : ContrastResults instance\n",
      "     |          The results for the test are attributes of this results instance.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import numpy as np\n",
      "     |      >>> import statsmodels.api as sm\n",
      "     |      >>> data = sm.datasets.longley.load()\n",
      "     |      >>> data.exog = sm.add_constant(data.exog)\n",
      "     |      >>> results = sm.OLS(data.endog, data.exog).fit()\n",
      "     |      >>> A = np.identity(len(results.params))\n",
      "     |      >>> A = A[1:,:]\n",
      "     |      \n",
      "     |      This tests that each coefficient is jointly statistically\n",
      "     |      significantly different from zero.\n",
      "     |      \n",
      "     |      >>> print(results.f_test(A))\n",
      "     |      <F test: F=array([[ 330.28533923]]), p=4.984030528700946e-10, df_denom=9, df_num=6>\n",
      "     |      \n",
      "     |      Compare this to\n",
      "     |      \n",
      "     |      >>> results.fvalue\n",
      "     |      330.2853392346658\n",
      "     |      >>> results.f_pvalue\n",
      "     |      4.98403096572e-10\n",
      "     |      \n",
      "     |      >>> B = np.array(([0,0,1,-1,0,0,0],[0,0,0,0,0,1,-1]))\n",
      "     |      \n",
      "     |      This tests that the coefficient on the 2nd and 3rd regressors are\n",
      "     |      equal and jointly that the coefficient on the 5th and 6th regressors\n",
      "     |      are equal.\n",
      "     |      \n",
      "     |      >>> print(results.f_test(B))\n",
      "     |      <F test: F=array([[ 9.74046187]]), p=0.005605288531708235, df_denom=9, df_num=2>\n",
      "     |      \n",
      "     |      Alternatively, you can specify the hypothesis tests using a string\n",
      "     |      \n",
      "     |      >>> from statsmodels.datasets import longley\n",
      "     |      >>> from statsmodels.formula.api import ols\n",
      "     |      >>> dta = longley.load_pandas().data\n",
      "     |      >>> formula = 'TOTEMP ~ GNPDEFL + GNP + UNEMP + ARMED + POP + YEAR'\n",
      "     |      >>> results = ols(formula, dta).fit()\n",
      "     |      >>> hypotheses = '(GNPDEFL = GNP), (UNEMP = 2), (YEAR/1829 = 1)'\n",
      "     |      >>> f_test = results.f_test(hypotheses)\n",
      "     |      >>> print(f_test)\n",
      "     |      <F test: F=array([[ 144.17976065]]), p=6.322026217355609e-08, df_denom=9, df_num=3>\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      statsmodels.stats.contrast.ContrastResults\n",
      "     |      wald_test\n",
      "     |      t_test\n",
      "     |      patsy.DesignInfo.linear_constraint\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The matrix `r_matrix` is assumed to be non-singular. More precisely,\n",
      "     |      \n",
      "     |      r_matrix (pX pX.T) r_matrix.T\n",
      "     |      \n",
      "     |      is assumed invertible. Here, pX is the generalized inverse of the\n",
      "     |      design matrix of the model. There can be problems in non-OLS models\n",
      "     |      where the rank of the covariance of the noise is not full.\n",
      "     |  \n",
      "     |  llf(self)\n",
      "     |  \n",
      "     |  normalized_cov_params(self)\n",
      "     |  \n",
      "     |  pvalues(self)\n",
      "     |  \n",
      "     |  remove_data(self)\n",
      "     |      remove data arrays, all nobs arrays from result and model\n",
      "     |      \n",
      "     |      This reduces the size of the instance, so it can be pickled with less\n",
      "     |      memory. Currently tested for use with predict from an unpickled\n",
      "     |      results and model instance.\n",
      "     |      \n",
      "     |      .. warning:: Since data and some intermediate results have been removed\n",
      "     |         calculating new statistics that require them will raise exceptions.\n",
      "     |         The exception will occur the first time an attribute is accessed\n",
      "     |         that has been set to None.\n",
      "     |      \n",
      "     |      Not fully tested for time series models, tsa, and might delete too much\n",
      "     |      for prediction or not all that would be possible.\n",
      "     |      \n",
      "     |      The lists of arrays to delete are maintained as attributes of\n",
      "     |      the result and model instance, except for cached values. These\n",
      "     |      lists could be changed before calling remove_data.\n",
      "     |      \n",
      "     |      The attributes to remove are named in:\n",
      "     |      \n",
      "     |      model._data_attr : arrays attached to both the model instance\n",
      "     |          and the results instance with the same attribute name.\n",
      "     |      \n",
      "     |      result.data_in_cache : arrays that may exist as values in\n",
      "     |          result._cache (TODO : should privatize name)\n",
      "     |      \n",
      "     |      result._data_attr_model : arrays attached to the model\n",
      "     |          instance but not to the results instance\n",
      "     |  \n",
      "     |  save(self, fname, remove_data=False)\n",
      "     |      save a pickle of this instance\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname : string or filehandle\n",
      "     |          fname can be a string to a file path or filename, or a filehandle.\n",
      "     |      remove_data : bool\n",
      "     |          If False (default), then the instance is pickled without changes.\n",
      "     |          If True, then all arrays with length nobs are set to None before\n",
      "     |          pickling. See the remove_data method.\n",
      "     |          In some cases not all arrays will be set to None.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If remove_data is true and the model result does not implement a\n",
      "     |      remove_data method then this will raise an exception.\n",
      "     |  \n",
      "     |  t_test(self, r_matrix, cov_p=None, scale=None, use_t=None)\n",
      "     |      Compute a t-test for a each linear hypothesis of the form Rb = q\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      r_matrix : array-like, str, tuple\n",
      "     |          - array : If an array is given, a p x k 2d array or length k 1d\n",
      "     |            array specifying the linear restrictions. It is assumed\n",
      "     |            that the linear combination is equal to zero.\n",
      "     |          - str : The full hypotheses to test can be given as a string.\n",
      "     |            See the examples.\n",
      "     |          - tuple : A tuple of arrays in the form (R, q). If q is given,\n",
      "     |            can be either a scalar or a length p row vector.\n",
      "     |      cov_p : array-like, optional\n",
      "     |          An alternative estimate for the parameter covariance matrix.\n",
      "     |          If None is given, self.normalized_cov_params is used.\n",
      "     |      scale : float, optional\n",
      "     |          An optional `scale` to use.  Default is the scale specified\n",
      "     |          by the model fit.\n",
      "     |      use_t : bool, optional\n",
      "     |          If use_t is None, then the default of the model is used.\n",
      "     |          If use_t is True, then the p-values are based on the t\n",
      "     |          distribution.\n",
      "     |          If use_t is False, then the p-values are based on the normal\n",
      "     |          distribution.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      res : ContrastResults instance\n",
      "     |          The results for the test are attributes of this results instance.\n",
      "     |          The available results have the same elements as the parameter table\n",
      "     |          in `summary()`.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import numpy as np\n",
      "     |      >>> import statsmodels.api as sm\n",
      "     |      >>> data = sm.datasets.longley.load()\n",
      "     |      >>> data.exog = sm.add_constant(data.exog)\n",
      "     |      >>> results = sm.OLS(data.endog, data.exog).fit()\n",
      "     |      >>> r = np.zeros_like(results.params)\n",
      "     |      >>> r[5:] = [1,-1]\n",
      "     |      >>> print(r)\n",
      "     |      [ 0.  0.  0.  0.  0.  1. -1.]\n",
      "     |      \n",
      "     |      r tests that the coefficients on the 5th and 6th independent\n",
      "     |      variable are the same.\n",
      "     |      \n",
      "     |      >>> T_test = results.t_test(r)\n",
      "     |      >>> print(T_test)\n",
      "     |                                   Test for Constraints\n",
      "     |      ==============================================================================\n",
      "     |                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "     |      ------------------------------------------------------------------------------\n",
      "     |      c0         -1829.2026    455.391     -4.017      0.003   -2859.368    -799.037\n",
      "     |      ==============================================================================\n",
      "     |      >>> T_test.effect\n",
      "     |      -1829.2025687192481\n",
      "     |      >>> T_test.sd\n",
      "     |      455.39079425193762\n",
      "     |      >>> T_test.tvalue\n",
      "     |      -4.0167754636411717\n",
      "     |      >>> T_test.pvalue\n",
      "     |      0.0015163772380899498\n",
      "     |      \n",
      "     |      Alternatively, you can specify the hypothesis tests using a string\n",
      "     |      \n",
      "     |      >>> from statsmodels.formula.api import ols\n",
      "     |      >>> dta = sm.datasets.longley.load_pandas().data\n",
      "     |      >>> formula = 'TOTEMP ~ GNPDEFL + GNP + UNEMP + ARMED + POP + YEAR'\n",
      "     |      >>> results = ols(formula, dta).fit()\n",
      "     |      >>> hypotheses = 'GNPDEFL = GNP, UNEMP = 2, YEAR/1829 = 1'\n",
      "     |      >>> t_test = results.t_test(hypotheses)\n",
      "     |      >>> print(t_test)\n",
      "     |                                   Test for Constraints\n",
      "     |      ==============================================================================\n",
      "     |                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "     |      ------------------------------------------------------------------------------\n",
      "     |      c0            15.0977     84.937      0.178      0.863    -177.042     207.238\n",
      "     |      c1            -2.0202      0.488     -8.231      0.000      -3.125      -0.915\n",
      "     |      c2             1.0001      0.249      0.000      1.000       0.437       1.563\n",
      "     |      ==============================================================================\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      ---------\n",
      "     |      tvalues : individual t statistics\n",
      "     |      f_test : for F tests\n",
      "     |      patsy.DesignInfo.linear_constraint\n",
      "     |  \n",
      "     |  t_test_pairwise(self, term_name, method='hs', alpha=0.05, factor_labels=None)\n",
      "     |      perform pairwise t_test with multiple testing corrected p-values\n",
      "     |      \n",
      "     |      This uses the formula design_info encoding contrast matrix and should\n",
      "     |      work for all encodings of a main effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      result : result instance\n",
      "     |          The results of an estimated model with a categorical main effect.\n",
      "     |      term_name : str\n",
      "     |          name of the term for which pairwise comparisons are computed.\n",
      "     |          Term names for categorical effects are created by patsy and\n",
      "     |          correspond to the main part of the exog names.\n",
      "     |      method : str or list of strings\n",
      "     |          multiple testing p-value correction, default is 'hs',\n",
      "     |          see stats.multipletesting\n",
      "     |      alpha : float\n",
      "     |          significance level for multiple testing reject decision.\n",
      "     |      factor_labels : None, list of str\n",
      "     |          Labels for the factor levels used for pairwise labels. If not\n",
      "     |          provided, then the labels from the formula design_info are used.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      results : instance of a simple Results class\n",
      "     |          The results are stored as attributes, the main attributes are the\n",
      "     |          following two. Other attributes are added for debugging purposes\n",
      "     |          or as background information.\n",
      "     |      \n",
      "     |          - result_frame : pandas DataFrame with t_test results and multiple\n",
      "     |            testing corrected p-values.\n",
      "     |          - contrasts : matrix of constraints of the null hypothesis in the\n",
      "     |            t_test.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Status: experimental. Currently only checked for treatment coding with\n",
      "     |      and without specified reference level.\n",
      "     |      \n",
      "     |      Currently there are no multiple testing corrected confidence intervals\n",
      "     |      available.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> res = ols(\"np.log(Days+1) ~ C(Weight) + C(Duration)\", data).fit()\n",
      "     |      >>> pw = res.t_test_pairwise(\"C(Weight)\")\n",
      "     |      >>> pw.result_frame\n",
      "     |               coef   std err         t         P>|t|  Conf. Int. Low\n",
      "     |      2-1  0.632315  0.230003  2.749157  8.028083e-03        0.171563\n",
      "     |      3-1  1.302555  0.230003  5.663201  5.331513e-07        0.841803\n",
      "     |      3-2  0.670240  0.230003  2.914044  5.119126e-03        0.209488\n",
      "     |           Conf. Int. Upp.  pvalue-hs reject-hs\n",
      "     |      2-1         1.093067   0.010212      True\n",
      "     |      3-1         1.763307   0.000002      True\n",
      "     |      3-2         1.130992   0.010212      True\n",
      "     |  \n",
      "     |  tvalues(self)\n",
      "     |      Return the t-statistic for a given parameter estimate.\n",
      "     |  \n",
      "     |  wald_test(self, r_matrix, cov_p=None, scale=1.0, invcov=None, use_f=None)\n",
      "     |      Compute a Wald-test for a joint linear hypothesis.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      r_matrix : array-like, str, or tuple\n",
      "     |          - array : An r x k array where r is the number of restrictions to\n",
      "     |            test and k is the number of regressors. It is assumed that the\n",
      "     |            linear combination is equal to zero.\n",
      "     |          - str : The full hypotheses to test can be given as a string.\n",
      "     |            See the examples.\n",
      "     |          - tuple : A tuple of arrays in the form (R, q), ``q`` can be\n",
      "     |            either a scalar or a length p row vector.\n",
      "     |      cov_p : array-like, optional\n",
      "     |          An alternative estimate for the parameter covariance matrix.\n",
      "     |          If None is given, self.normalized_cov_params is used.\n",
      "     |      scale : float, optional\n",
      "     |          Default is 1.0 for no scaling.\n",
      "     |      invcov : array-like, optional\n",
      "     |          A q x q array to specify an inverse covariance matrix based on a\n",
      "     |          restrictions matrix.\n",
      "     |      use_f : bool\n",
      "     |          If True, then the F-distribution is used. If False, then the\n",
      "     |          asymptotic distribution, chisquare is used. If use_f is None, then\n",
      "     |          the F distribution is used if the model specifies that use_t is True.\n",
      "     |          The test statistic is proportionally adjusted for the distribution\n",
      "     |          by the number of constraints in the hypothesis.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      res : ContrastResults instance\n",
      "     |          The results for the test are attributes of this results instance.\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      statsmodels.stats.contrast.ContrastResults\n",
      "     |      f_test\n",
      "     |      t_test\n",
      "     |      patsy.DesignInfo.linear_constraint\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The matrix `r_matrix` is assumed to be non-singular. More precisely,\n",
      "     |      \n",
      "     |      r_matrix (pX pX.T) r_matrix.T\n",
      "     |      \n",
      "     |      is assumed invertible. Here, pX is the generalized inverse of the\n",
      "     |      design matrix of the model. There can be problems in non-OLS models\n",
      "     |      where the rank of the covariance of the noise is not full.\n",
      "     |  \n",
      "     |  wald_test_terms(self, skip_single=False, extra_constraints=None, combine_terms=None)\n",
      "     |      Compute a sequence of Wald tests for terms over multiple columns\n",
      "     |      \n",
      "     |      This computes joined Wald tests for the hypothesis that all\n",
      "     |      coefficients corresponding to a `term` are zero.\n",
      "     |      \n",
      "     |      `Terms` are defined by the underlying formula or by string matching.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      skip_single : boolean\n",
      "     |          If true, then terms that consist only of a single column and,\n",
      "     |          therefore, refers only to a single parameter is skipped.\n",
      "     |          If false, then all terms are included.\n",
      "     |      extra_constraints : ndarray\n",
      "     |          not tested yet\n",
      "     |      combine_terms : None or list of strings\n",
      "     |          Each string in this list is matched to the name of the terms or\n",
      "     |          the name of the exogenous variables. All columns whose name\n",
      "     |          includes that string are combined in one joint test.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      test_result : result instance\n",
      "     |          The result instance contains `table` which is a pandas DataFrame\n",
      "     |          with the test results: test statistic, degrees of freedom and\n",
      "     |          pvalues.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> res_ols = ols(\"np.log(Days+1) ~ C(Duration, Sum)*C(Weight, Sum)\", data).fit()\n",
      "     |      >>> res_ols.wald_test_terms()\n",
      "     |      <class 'statsmodels.stats.contrast.WaldTestResults'>\n",
      "     |                                                F                P>F  df constraint  df denom\n",
      "     |      Intercept                        279.754525  2.37985521351e-22              1        51\n",
      "     |      C(Duration, Sum)                   5.367071    0.0245738436636              1        51\n",
      "     |      C(Weight, Sum)                    12.432445  3.99943118767e-05              2        51\n",
      "     |      C(Duration, Sum):C(Weight, Sum)    0.176002      0.83912310946              2        51\n",
      "     |      \n",
      "     |      >>> res_poi = Poisson.from_formula(\"Days ~ C(Weight) * C(Duration)\",                                            data).fit(cov_type='HC0')\n",
      "     |      >>> wt = res_poi.wald_test_terms(skip_single=False,                                          combine_terms=['Duration', 'Weight'])\n",
      "     |      >>> print(wt)\n",
      "     |                                  chi2             P>chi2  df constraint\n",
      "     |      Intercept              15.695625  7.43960374424e-05              1\n",
      "     |      C(Weight)              16.132616  0.000313940174705              2\n",
      "     |      C(Duration)             1.009147     0.315107378931              1\n",
      "     |      C(Weight):C(Duration)   0.216694     0.897315972824              2\n",
      "     |      Duration               11.187849     0.010752286833              3\n",
      "     |      Weight                 30.263368  4.32586407145e-06              4\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from LikelihoodModelResults:\n",
      "     |  \n",
      "     |  load(fname) from builtins.type\n",
      "     |      load a pickle, (class method)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname : string or filehandle\n",
      "     |          fname can be a string to a file path or filename, or a filehandle.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      unpickled instance\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from LikelihoodModelResults:\n",
      "     |  \n",
      "     |  use_t = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Results:\n",
      "     |  \n",
      "     |  initialize(self, model, params, **kwd)\n",
      "     |  \n",
      "     |  predict(self, exog=None, transform=True, *args, **kwargs)\n",
      "     |      Call self.model.predict with self.params as the first argument.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      exog : array-like, optional\n",
      "     |          The values for which you want to predict. see Notes below.\n",
      "     |      transform : bool, optional\n",
      "     |          If the model was fit via a formula, do you want to pass\n",
      "     |          exog through the formula. Default is True. E.g., if you fit\n",
      "     |          a model y ~ log(x1) + log(x2), and transform is True, then\n",
      "     |          you can pass a data structure that contains x1 and x2 in\n",
      "     |          their original form. Otherwise, you'd need to log the data\n",
      "     |          first.\n",
      "     |      args, kwargs :\n",
      "     |          Some models can take additional arguments or keywords, see the\n",
      "     |          predict method of the model for the details.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      prediction : ndarray, pandas.Series or pandas.DataFrame\n",
      "     |          See self.model.predict\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The types of exog that are supported depends on whether a formula\n",
      "     |      was used in the specification of the model.\n",
      "     |      \n",
      "     |      If a formula was used, then exog is processed in the same way as\n",
      "     |      the original data. This transformation needs to have key access to the\n",
      "     |      same variable names, and can be a pandas DataFrame or a dict like\n",
      "     |      object.\n",
      "     |      \n",
      "     |      If no formula was used, then the provided exog needs to have the\n",
      "     |      same number of columns as the original exog in the model. No\n",
      "     |      transformation of the data is performed except converting it to\n",
      "     |      a numpy array.\n",
      "     |      \n",
      "     |      Row indices as in pandas data frames are supported, and added to the\n",
      "     |      returned prediction.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Results:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ResultMixin:\n",
      "     |  \n",
      "     |  aic(self)\n",
      "     |  \n",
      "     |  bic(self)\n",
      "     |  \n",
      "     |  bootstrap(self, nrep=100, method='nm', disp=0, store=1)\n",
      "     |      simple bootstrap to get mean and variance of estimator\n",
      "     |      \n",
      "     |      see notes\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      nrep : int\n",
      "     |          number of bootstrap replications\n",
      "     |      method : str\n",
      "     |          optimization method to use\n",
      "     |      disp : bool\n",
      "     |          If true, then optimization prints results\n",
      "     |      store : bool\n",
      "     |          If true, then parameter estimates for all bootstrap iterations\n",
      "     |          are attached in self.bootstrap_results\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      mean : array\n",
      "     |          mean of parameter estimates over bootstrap replications\n",
      "     |      std : array\n",
      "     |          standard deviation of parameter estimates over bootstrap\n",
      "     |          replications\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This was mainly written to compare estimators of the standard errors of\n",
      "     |      the parameter estimates.  It uses independent random sampling from the\n",
      "     |      original endog and exog, and therefore is only correct if observations\n",
      "     |      are independently distributed.\n",
      "     |      \n",
      "     |      This will be moved to apply only to models with independently\n",
      "     |      distributed observations.\n",
      "     |  \n",
      "     |  bsejac(self)\n",
      "     |      standard deviation of parameter estimates based on covjac\n",
      "     |  \n",
      "     |  bsejhj(self)\n",
      "     |      standard deviation of parameter estimates based on covHJH\n",
      "     |  \n",
      "     |  covjac(self)\n",
      "     |      covariance of parameters based on outer product of jacobian of\n",
      "     |      log-likelihood\n",
      "     |  \n",
      "     |  covjhj(self)\n",
      "     |      covariance of parameters based on HJJH\n",
      "     |      \n",
      "     |      dot product of Hessian, Jacobian, Jacobian, Hessian of likelihood\n",
      "     |      \n",
      "     |      name should be covhjh\n",
      "     |  \n",
      "     |  df_modelwc(self)\n",
      "     |  \n",
      "     |  get_nlfun(self, fun)\n",
      "     |  \n",
      "     |  hessv(self)\n",
      "     |      cached Hessian of log-likelihood\n",
      "     |  \n",
      "     |  score_obsv(self)\n",
      "     |      cached Jacobian of log-likelihood\n",
      "    \n",
      "    class LikelihoodModel(Model)\n",
      "     |  LikelihoodModel(endog, exog=None, **kwargs)\n",
      "     |  \n",
      "     |  Likelihood model is a subclass of Model.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LikelihoodModel\n",
      "     |      Model\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, exog=None, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self, start_params=None, method='newton', maxiter=100, full_output=True, disp=True, fargs=(), callback=None, retall=False, skip_hessian=False, **kwargs)\n",
      "     |      Fit method for likelihood based models\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      start_params : array-like, optional\n",
      "     |          Initial guess of the solution for the loglikelihood maximization.\n",
      "     |          The default is an array of zeros.\n",
      "     |      method : str, optional\n",
      "     |          The `method` determines which solver from `scipy.optimize`\n",
      "     |          is used, and it can be chosen from among the following strings:\n",
      "     |      \n",
      "     |          - 'newton' for Newton-Raphson, 'nm' for Nelder-Mead\n",
      "     |          - 'bfgs' for Broyden-Fletcher-Goldfarb-Shanno (BFGS)\n",
      "     |          - 'lbfgs' for limited-memory BFGS with optional box constraints\n",
      "     |          - 'powell' for modified Powell's method\n",
      "     |          - 'cg' for conjugate gradient\n",
      "     |          - 'ncg' for Newton-conjugate gradient\n",
      "     |          - 'basinhopping' for global basin-hopping solver\n",
      "     |          - 'minimize' for generic wrapper of scipy minimize (BFGS by default)\n",
      "     |      \n",
      "     |          The explicit arguments in `fit` are passed to the solver,\n",
      "     |          with the exception of the basin-hopping solver. Each\n",
      "     |          solver has several optional arguments that are not the same across\n",
      "     |          solvers. See the notes section below (or scipy.optimize) for the\n",
      "     |          available arguments and for the list of explicit arguments that the\n",
      "     |          basin-hopping solver supports.\n",
      "     |      maxiter : int, optional\n",
      "     |          The maximum number of iterations to perform.\n",
      "     |      full_output : bool, optional\n",
      "     |          Set to True to have all available output in the Results object's\n",
      "     |          mle_retvals attribute. The output is dependent on the solver.\n",
      "     |          See LikelihoodModelResults notes section for more information.\n",
      "     |      disp : bool, optional\n",
      "     |          Set to True to print convergence messages.\n",
      "     |      fargs : tuple, optional\n",
      "     |          Extra arguments passed to the likelihood function, i.e.,\n",
      "     |          loglike(x,*args)\n",
      "     |      callback : callable callback(xk), optional\n",
      "     |          Called after each iteration, as callback(xk), where xk is the\n",
      "     |          current parameter vector.\n",
      "     |      retall : bool, optional\n",
      "     |          Set to True to return list of solutions at each iteration.\n",
      "     |          Available in Results object's mle_retvals attribute.\n",
      "     |      skip_hessian : bool, optional\n",
      "     |          If False (default), then the negative inverse hessian is calculated\n",
      "     |          after the optimization. If True, then the hessian will not be\n",
      "     |          calculated. However, it will be available in methods that use the\n",
      "     |          hessian in the optimization (currently only with `\"newton\"`).\n",
      "     |      kwargs : keywords\n",
      "     |          All kwargs are passed to the chosen solver with one exception. The\n",
      "     |          following keyword controls what happens after the fit::\n",
      "     |      \n",
      "     |              warn_convergence : bool, optional\n",
      "     |                  If True, checks the model for the converged flag. If the\n",
      "     |                  converged flag is False, a ConvergenceWarning is issued.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The 'basinhopping' solver ignores `maxiter`, `retall`, `full_output`\n",
      "     |      explicit arguments.\n",
      "     |      \n",
      "     |      Optional arguments for solvers (see returned Results.mle_settings)::\n",
      "     |      \n",
      "     |          'newton'\n",
      "     |              tol : float\n",
      "     |                  Relative error in params acceptable for convergence.\n",
      "     |          'nm' -- Nelder Mead\n",
      "     |              xtol : float\n",
      "     |                  Relative error in params acceptable for convergence\n",
      "     |              ftol : float\n",
      "     |                  Relative error in loglike(params) acceptable for\n",
      "     |                  convergence\n",
      "     |              maxfun : int\n",
      "     |                  Maximum number of function evaluations to make.\n",
      "     |          'bfgs'\n",
      "     |              gtol : float\n",
      "     |                  Stop when norm of gradient is less than gtol.\n",
      "     |              norm : float\n",
      "     |                  Order of norm (np.Inf is max, -np.Inf is min)\n",
      "     |              epsilon\n",
      "     |                  If fprime is approximated, use this value for the step\n",
      "     |                  size. Only relevant if LikelihoodModel.score is None.\n",
      "     |          'lbfgs'\n",
      "     |              m : int\n",
      "     |                  This many terms are used for the Hessian approximation.\n",
      "     |              factr : float\n",
      "     |                  A stop condition that is a variant of relative error.\n",
      "     |              pgtol : float\n",
      "     |                  A stop condition that uses the projected gradient.\n",
      "     |              epsilon\n",
      "     |                  If fprime is approximated, use this value for the step\n",
      "     |                  size. Only relevant if LikelihoodModel.score is None.\n",
      "     |              maxfun : int\n",
      "     |                  Maximum number of function evaluations to make.\n",
      "     |              bounds : sequence\n",
      "     |                  (min, max) pairs for each element in x,\n",
      "     |                  defining the bounds on that parameter.\n",
      "     |                  Use None for one of min or max when there is no bound\n",
      "     |                  in that direction.\n",
      "     |          'cg'\n",
      "     |              gtol : float\n",
      "     |                  Stop when norm of gradient is less than gtol.\n",
      "     |              norm : float\n",
      "     |                  Order of norm (np.Inf is max, -np.Inf is min)\n",
      "     |              epsilon : float\n",
      "     |                  If fprime is approximated, use this value for the step\n",
      "     |                  size. Can be scalar or vector.  Only relevant if\n",
      "     |                  Likelihoodmodel.score is None.\n",
      "     |          'ncg'\n",
      "     |              fhess_p : callable f'(x,*args)\n",
      "     |                  Function which computes the Hessian of f times an arbitrary\n",
      "     |                  vector, p.  Should only be supplied if\n",
      "     |                  LikelihoodModel.hessian is None.\n",
      "     |              avextol : float\n",
      "     |                  Stop when the average relative error in the minimizer\n",
      "     |                  falls below this amount.\n",
      "     |              epsilon : float or ndarray\n",
      "     |                  If fhess is approximated, use this value for the step size.\n",
      "     |                  Only relevant if Likelihoodmodel.hessian is None.\n",
      "     |          'powell'\n",
      "     |              xtol : float\n",
      "     |                  Line-search error tolerance\n",
      "     |              ftol : float\n",
      "     |                  Relative error in loglike(params) for acceptable for\n",
      "     |                  convergence.\n",
      "     |              maxfun : int\n",
      "     |                  Maximum number of function evaluations to make.\n",
      "     |              start_direc : ndarray\n",
      "     |                  Initial direction set.\n",
      "     |          'basinhopping'\n",
      "     |              niter : integer\n",
      "     |                  The number of basin hopping iterations.\n",
      "     |              niter_success : integer\n",
      "     |                  Stop the run if the global minimum candidate remains the\n",
      "     |                  same for this number of iterations.\n",
      "     |              T : float\n",
      "     |                  The \"temperature\" parameter for the accept or reject\n",
      "     |                  criterion. Higher \"temperatures\" mean that larger jumps\n",
      "     |                  in function value will be accepted. For best results\n",
      "     |                  `T` should be comparable to the separation (in function\n",
      "     |                  value) between local minima.\n",
      "     |              stepsize : float\n",
      "     |                  Initial step size for use in the random displacement.\n",
      "     |              interval : integer\n",
      "     |                  The interval for how often to update the `stepsize`.\n",
      "     |              minimizer : dict\n",
      "     |                  Extra keyword arguments to be passed to the minimizer\n",
      "     |                  `scipy.optimize.minimize()`, for example 'method' - the\n",
      "     |                  minimization method (e.g. 'L-BFGS-B'), or 'tol' - the\n",
      "     |                  tolerance for termination. Other arguments are mapped from\n",
      "     |                  explicit argument of `fit`:\n",
      "     |                    - `args` <- `fargs`\n",
      "     |                    - `jac` <- `score`\n",
      "     |                    - `hess` <- `hess`\n",
      "     |          'minimize'\n",
      "     |              min_method : str, optional\n",
      "     |                  Name of minimization method to use.\n",
      "     |                  Any method specific arguments can be passed directly.\n",
      "     |                  For a list of methods and their arguments, see\n",
      "     |                  documentation of `scipy.optimize.minimize`.\n",
      "     |                  If no method is specified, then BFGS is used.\n",
      "     |  \n",
      "     |  hessian(self, params)\n",
      "     |      The Hessian matrix of the model\n",
      "     |  \n",
      "     |  information(self, params)\n",
      "     |      Fisher information matrix of model\n",
      "     |      \n",
      "     |      Returns -Hessian of loglike evaluated at params.\n",
      "     |  \n",
      "     |  initialize(self)\n",
      "     |      Initialize (possibly re-initialize) a Model instance. For\n",
      "     |      instance, the design matrix of a linear model may change\n",
      "     |      and some things must be recomputed.\n",
      "     |  \n",
      "     |  loglike(self, params)\n",
      "     |      Log-likelihood of model.\n",
      "     |  \n",
      "     |  score(self, params)\n",
      "     |      Score vector of model.\n",
      "     |      \n",
      "     |      The gradient of logL with respect to each parameter.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Model:\n",
      "     |  \n",
      "     |  predict(self, params, exog=None, *args, **kwargs)\n",
      "     |      After a model has been fit predict returns the fitted values.\n",
      "     |      \n",
      "     |      This is a placeholder intended to be overwritten by individual models.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Model:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      "     |      Create a Model from a formula and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model\n",
      "     |      data : array-like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      subset : array-like\n",
      "     |          An array-like object of booleans, integers, or index values that\n",
      "     |          indicate the subset of df to use in the model. Assumes df is a\n",
      "     |          `pandas.DataFrame`\n",
      "     |      drop_cols : array-like\n",
      "     |          Columns to drop from the design matrix.  Cannot be used to\n",
      "     |          drop terms involving categoricals.\n",
      "     |      args : extra arguments\n",
      "     |          These are passed to the model\n",
      "     |      kwargs : extra keyword arguments\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model : Model instance\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      ------\n",
      "     |      data must define __getitem__ with the keys in the formula terms\n",
      "     |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      "     |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Model:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      Names of exogenous variables\n",
      "    \n",
      "    class LikelihoodModelResults(Results)\n",
      "     |  LikelihoodModelResults(model, params, normalized_cov_params=None, scale=1.0, **kwargs)\n",
      "     |  \n",
      "     |  Class to contain results from likelihood models\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  -----------\n",
      "     |  model : LikelihoodModel instance or subclass instance\n",
      "     |      LikelihoodModelResults holds a reference to the model that is fit.\n",
      "     |  params : 1d array_like\n",
      "     |      parameter estimates from estimated model\n",
      "     |  normalized_cov_params : 2d array\n",
      "     |     Normalized (before scaling) covariance of params. (dot(X.T,X))**-1\n",
      "     |  scale : float\n",
      "     |      For (some subset of models) scale will typically be the\n",
      "     |      mean square error from the estimated model (sigma^2)\n",
      "     |  \n",
      "     |  Returns\n",
      "     |  -------\n",
      "     |  **Attributes**\n",
      "     |  mle_retvals : dict\n",
      "     |      Contains the values returned from the chosen optimization method if\n",
      "     |      full_output is True during the fit.  Available only if the model\n",
      "     |      is fit by maximum likelihood.  See notes below for the output from\n",
      "     |      the different methods.\n",
      "     |  mle_settings : dict\n",
      "     |      Contains the arguments passed to the chosen optimization method.\n",
      "     |      Available if the model is fit by maximum likelihood.  See\n",
      "     |      LikelihoodModel.fit for more information.\n",
      "     |  model : model instance\n",
      "     |      LikelihoodResults contains a reference to the model that is fit.\n",
      "     |  params : ndarray\n",
      "     |      The parameters estimated for the model.\n",
      "     |  scale : float\n",
      "     |      The scaling factor of the model given during instantiation.\n",
      "     |  tvalues : array\n",
      "     |      The t-values of the standard errors.\n",
      "     |  \n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  The covariance of params is given by scale times normalized_cov_params.\n",
      "     |  \n",
      "     |  Return values by solver if full_output is True during fit:\n",
      "     |  \n",
      "     |      'newton'\n",
      "     |          fopt : float\n",
      "     |              The value of the (negative) loglikelihood at its\n",
      "     |              minimum.\n",
      "     |          iterations : int\n",
      "     |              Number of iterations performed.\n",
      "     |          score : ndarray\n",
      "     |              The score vector at the optimum.\n",
      "     |          Hessian : ndarray\n",
      "     |              The Hessian at the optimum.\n",
      "     |          warnflag : int\n",
      "     |              1 if maxiter is exceeded. 0 if successful convergence.\n",
      "     |          converged : bool\n",
      "     |              True: converged. False: did not converge.\n",
      "     |          allvecs : list\n",
      "     |              List of solutions at each iteration.\n",
      "     |      'nm'\n",
      "     |          fopt : float\n",
      "     |              The value of the (negative) loglikelihood at its\n",
      "     |              minimum.\n",
      "     |          iterations : int\n",
      "     |              Number of iterations performed.\n",
      "     |          warnflag : int\n",
      "     |              1: Maximum number of function evaluations made.\n",
      "     |              2: Maximum number of iterations reached.\n",
      "     |          converged : bool\n",
      "     |              True: converged. False: did not converge.\n",
      "     |          allvecs : list\n",
      "     |              List of solutions at each iteration.\n",
      "     |      'bfgs'\n",
      "     |          fopt : float\n",
      "     |              Value of the (negative) loglikelihood at its minimum.\n",
      "     |          gopt : float\n",
      "     |              Value of gradient at minimum, which should be near 0.\n",
      "     |          Hinv : ndarray\n",
      "     |              value of the inverse Hessian matrix at minimum.  Note\n",
      "     |              that this is just an approximation and will often be\n",
      "     |              different from the value of the analytic Hessian.\n",
      "     |          fcalls : int\n",
      "     |              Number of calls to loglike.\n",
      "     |          gcalls : int\n",
      "     |              Number of calls to gradient/score.\n",
      "     |          warnflag : int\n",
      "     |              1: Maximum number of iterations exceeded. 2: Gradient\n",
      "     |              and/or function calls are not changing.\n",
      "     |          converged : bool\n",
      "     |              True: converged.  False: did not converge.\n",
      "     |          allvecs : list\n",
      "     |              Results at each iteration.\n",
      "     |      'lbfgs'\n",
      "     |          fopt : float\n",
      "     |              Value of the (negative) loglikelihood at its minimum.\n",
      "     |          gopt : float\n",
      "     |              Value of gradient at minimum, which should be near 0.\n",
      "     |          fcalls : int\n",
      "     |              Number of calls to loglike.\n",
      "     |          warnflag : int\n",
      "     |              Warning flag:\n",
      "     |  \n",
      "     |              - 0 if converged\n",
      "     |              - 1 if too many function evaluations or too many iterations\n",
      "     |              - 2 if stopped for another reason\n",
      "     |  \n",
      "     |          converged : bool\n",
      "     |              True: converged.  False: did not converge.\n",
      "     |      'powell'\n",
      "     |          fopt : float\n",
      "     |              Value of the (negative) loglikelihood at its minimum.\n",
      "     |          direc : ndarray\n",
      "     |              Current direction set.\n",
      "     |          iterations : int\n",
      "     |              Number of iterations performed.\n",
      "     |          fcalls : int\n",
      "     |              Number of calls to loglike.\n",
      "     |          warnflag : int\n",
      "     |              1: Maximum number of function evaluations. 2: Maximum number\n",
      "     |              of iterations.\n",
      "     |          converged : bool\n",
      "     |              True : converged. False: did not converge.\n",
      "     |          allvecs : list\n",
      "     |              Results at each iteration.\n",
      "     |      'cg'\n",
      "     |          fopt : float\n",
      "     |              Value of the (negative) loglikelihood at its minimum.\n",
      "     |          fcalls : int\n",
      "     |              Number of calls to loglike.\n",
      "     |          gcalls : int\n",
      "     |              Number of calls to gradient/score.\n",
      "     |          warnflag : int\n",
      "     |              1: Maximum number of iterations exceeded. 2: Gradient and/\n",
      "     |              or function calls not changing.\n",
      "     |          converged : bool\n",
      "     |              True: converged. False: did not converge.\n",
      "     |          allvecs : list\n",
      "     |              Results at each iteration.\n",
      "     |      'ncg'\n",
      "     |          fopt : float\n",
      "     |              Value of the (negative) loglikelihood at its minimum.\n",
      "     |          fcalls : int\n",
      "     |              Number of calls to loglike.\n",
      "     |          gcalls : int\n",
      "     |              Number of calls to gradient/score.\n",
      "     |          hcalls : int\n",
      "     |              Number of calls to hessian.\n",
      "     |          warnflag : int\n",
      "     |              1: Maximum number of iterations exceeded.\n",
      "     |          converged : bool\n",
      "     |              True: converged. False: did not converge.\n",
      "     |          allvecs : list\n",
      "     |              Results at each iteration.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LikelihoodModelResults\n",
      "     |      Results\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, model, params, normalized_cov_params=None, scale=1.0, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  bse(self)\n",
      "     |  \n",
      "     |  conf_int(self, alpha=0.05, cols=None, method='default')\n",
      "     |      Returns the confidence interval of the fitted parameters.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      alpha : float, optional\n",
      "     |          The significance level for the confidence interval.\n",
      "     |          ie., The default `alpha` = .05 returns a 95% confidence interval.\n",
      "     |      cols : array-like, optional\n",
      "     |          `cols` specifies which confidence intervals to return\n",
      "     |      method : string\n",
      "     |          Not Implemented Yet\n",
      "     |          Method to estimate the confidence_interval.\n",
      "     |          \"Default\" : uses self.bse which is based on inverse Hessian for MLE\n",
      "     |          \"hjjh\" :\n",
      "     |          \"jac\" :\n",
      "     |          \"boot-bse\"\n",
      "     |          \"boot_quant\"\n",
      "     |          \"profile\"\n",
      "     |      \n",
      "     |      \n",
      "     |      Returns\n",
      "     |      --------\n",
      "     |      conf_int : array\n",
      "     |          Each row contains [lower, upper] limits of the confidence interval\n",
      "     |          for the corresponding parameter. The first column contains all\n",
      "     |          lower, the second column contains all upper limits.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import statsmodels.api as sm\n",
      "     |      >>> data = sm.datasets.longley.load()\n",
      "     |      >>> data.exog = sm.add_constant(data.exog)\n",
      "     |      >>> results = sm.OLS(data.endog, data.exog).fit()\n",
      "     |      >>> results.conf_int()\n",
      "     |      array([[-5496529.48322745, -1467987.78596704],\n",
      "     |             [    -177.02903529,      207.15277984],\n",
      "     |             [      -0.1115811 ,        0.03994274],\n",
      "     |             [      -3.12506664,       -0.91539297],\n",
      "     |             [      -1.5179487 ,       -0.54850503],\n",
      "     |             [      -0.56251721,        0.460309  ],\n",
      "     |             [     798.7875153 ,     2859.51541392]])\n",
      "     |      \n",
      "     |      \n",
      "     |      >>> results.conf_int(cols=(2,3))\n",
      "     |      array([[-0.1115811 ,  0.03994274],\n",
      "     |             [-3.12506664, -0.91539297]])\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The confidence interval is based on the standard normal distribution.\n",
      "     |      Models wish to use a different distribution should overwrite this\n",
      "     |      method.\n",
      "     |  \n",
      "     |  cov_params(self, r_matrix=None, column=None, scale=None, cov_p=None, other=None)\n",
      "     |      Returns the variance/covariance matrix.\n",
      "     |      \n",
      "     |      The variance/covariance matrix can be of a linear contrast\n",
      "     |      of the estimates of params or all params multiplied by scale which\n",
      "     |      will usually be an estimate of sigma^2.  Scale is assumed to be\n",
      "     |      a scalar.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      r_matrix : array-like\n",
      "     |          Can be 1d, or 2d.  Can be used alone or with other.\n",
      "     |      column :  array-like, optional\n",
      "     |          Must be used on its own.  Can be 0d or 1d see below.\n",
      "     |      scale : float, optional\n",
      "     |          Can be specified or not.  Default is None, which means that\n",
      "     |          the scale argument is taken from the model.\n",
      "     |      other : array-like, optional\n",
      "     |          Can be used when r_matrix is specified.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      cov : ndarray\n",
      "     |          covariance matrix of the parameter estimates or of linear\n",
      "     |          combination of parameter estimates. See Notes.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      (The below are assumed to be in matrix notation.)\n",
      "     |      \n",
      "     |      If no argument is specified returns the covariance matrix of a model\n",
      "     |      ``(scale)*(X.T X)^(-1)``\n",
      "     |      \n",
      "     |      If contrast is specified it pre and post-multiplies as follows\n",
      "     |      ``(scale) * r_matrix (X.T X)^(-1) r_matrix.T``\n",
      "     |      \n",
      "     |      If contrast and other are specified returns\n",
      "     |      ``(scale) * r_matrix (X.T X)^(-1) other.T``\n",
      "     |      \n",
      "     |      If column is specified returns\n",
      "     |      ``(scale) * (X.T X)^(-1)[column,column]`` if column is 0d\n",
      "     |      \n",
      "     |      OR\n",
      "     |      \n",
      "     |      ``(scale) * (X.T X)^(-1)[column][:,column]`` if column is 1d\n",
      "     |  \n",
      "     |  f_test(self, r_matrix, cov_p=None, scale=1.0, invcov=None)\n",
      "     |      Compute the F-test for a joint linear hypothesis.\n",
      "     |      \n",
      "     |      This is a special case of `wald_test` that always uses the F\n",
      "     |      distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      r_matrix : array-like, str, or tuple\n",
      "     |          - array : An r x k array where r is the number of restrictions to\n",
      "     |            test and k is the number of regressors. It is assumed\n",
      "     |            that the linear combination is equal to zero.\n",
      "     |          - str : The full hypotheses to test can be given as a string.\n",
      "     |            See the examples.\n",
      "     |          - tuple : A tuple of arrays in the form (R, q), ``q`` can be\n",
      "     |            either a scalar or a length k row vector.\n",
      "     |      cov_p : array-like, optional\n",
      "     |          An alternative estimate for the parameter covariance matrix.\n",
      "     |          If None is given, self.normalized_cov_params is used.\n",
      "     |      scale : float, optional\n",
      "     |          Default is 1.0 for no scaling.\n",
      "     |      invcov : array-like, optional\n",
      "     |          A q x q array to specify an inverse covariance matrix based on a\n",
      "     |          restrictions matrix.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      res : ContrastResults instance\n",
      "     |          The results for the test are attributes of this results instance.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import numpy as np\n",
      "     |      >>> import statsmodels.api as sm\n",
      "     |      >>> data = sm.datasets.longley.load()\n",
      "     |      >>> data.exog = sm.add_constant(data.exog)\n",
      "     |      >>> results = sm.OLS(data.endog, data.exog).fit()\n",
      "     |      >>> A = np.identity(len(results.params))\n",
      "     |      >>> A = A[1:,:]\n",
      "     |      \n",
      "     |      This tests that each coefficient is jointly statistically\n",
      "     |      significantly different from zero.\n",
      "     |      \n",
      "     |      >>> print(results.f_test(A))\n",
      "     |      <F test: F=array([[ 330.28533923]]), p=4.984030528700946e-10, df_denom=9, df_num=6>\n",
      "     |      \n",
      "     |      Compare this to\n",
      "     |      \n",
      "     |      >>> results.fvalue\n",
      "     |      330.2853392346658\n",
      "     |      >>> results.f_pvalue\n",
      "     |      4.98403096572e-10\n",
      "     |      \n",
      "     |      >>> B = np.array(([0,0,1,-1,0,0,0],[0,0,0,0,0,1,-1]))\n",
      "     |      \n",
      "     |      This tests that the coefficient on the 2nd and 3rd regressors are\n",
      "     |      equal and jointly that the coefficient on the 5th and 6th regressors\n",
      "     |      are equal.\n",
      "     |      \n",
      "     |      >>> print(results.f_test(B))\n",
      "     |      <F test: F=array([[ 9.74046187]]), p=0.005605288531708235, df_denom=9, df_num=2>\n",
      "     |      \n",
      "     |      Alternatively, you can specify the hypothesis tests using a string\n",
      "     |      \n",
      "     |      >>> from statsmodels.datasets import longley\n",
      "     |      >>> from statsmodels.formula.api import ols\n",
      "     |      >>> dta = longley.load_pandas().data\n",
      "     |      >>> formula = 'TOTEMP ~ GNPDEFL + GNP + UNEMP + ARMED + POP + YEAR'\n",
      "     |      >>> results = ols(formula, dta).fit()\n",
      "     |      >>> hypotheses = '(GNPDEFL = GNP), (UNEMP = 2), (YEAR/1829 = 1)'\n",
      "     |      >>> f_test = results.f_test(hypotheses)\n",
      "     |      >>> print(f_test)\n",
      "     |      <F test: F=array([[ 144.17976065]]), p=6.322026217355609e-08, df_denom=9, df_num=3>\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      statsmodels.stats.contrast.ContrastResults\n",
      "     |      wald_test\n",
      "     |      t_test\n",
      "     |      patsy.DesignInfo.linear_constraint\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The matrix `r_matrix` is assumed to be non-singular. More precisely,\n",
      "     |      \n",
      "     |      r_matrix (pX pX.T) r_matrix.T\n",
      "     |      \n",
      "     |      is assumed invertible. Here, pX is the generalized inverse of the\n",
      "     |      design matrix of the model. There can be problems in non-OLS models\n",
      "     |      where the rank of the covariance of the noise is not full.\n",
      "     |  \n",
      "     |  llf(self)\n",
      "     |  \n",
      "     |  normalized_cov_params(self)\n",
      "     |  \n",
      "     |  pvalues(self)\n",
      "     |  \n",
      "     |  remove_data(self)\n",
      "     |      remove data arrays, all nobs arrays from result and model\n",
      "     |      \n",
      "     |      This reduces the size of the instance, so it can be pickled with less\n",
      "     |      memory. Currently tested for use with predict from an unpickled\n",
      "     |      results and model instance.\n",
      "     |      \n",
      "     |      .. warning:: Since data and some intermediate results have been removed\n",
      "     |         calculating new statistics that require them will raise exceptions.\n",
      "     |         The exception will occur the first time an attribute is accessed\n",
      "     |         that has been set to None.\n",
      "     |      \n",
      "     |      Not fully tested for time series models, tsa, and might delete too much\n",
      "     |      for prediction or not all that would be possible.\n",
      "     |      \n",
      "     |      The lists of arrays to delete are maintained as attributes of\n",
      "     |      the result and model instance, except for cached values. These\n",
      "     |      lists could be changed before calling remove_data.\n",
      "     |      \n",
      "     |      The attributes to remove are named in:\n",
      "     |      \n",
      "     |      model._data_attr : arrays attached to both the model instance\n",
      "     |          and the results instance with the same attribute name.\n",
      "     |      \n",
      "     |      result.data_in_cache : arrays that may exist as values in\n",
      "     |          result._cache (TODO : should privatize name)\n",
      "     |      \n",
      "     |      result._data_attr_model : arrays attached to the model\n",
      "     |          instance but not to the results instance\n",
      "     |  \n",
      "     |  save(self, fname, remove_data=False)\n",
      "     |      save a pickle of this instance\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname : string or filehandle\n",
      "     |          fname can be a string to a file path or filename, or a filehandle.\n",
      "     |      remove_data : bool\n",
      "     |          If False (default), then the instance is pickled without changes.\n",
      "     |          If True, then all arrays with length nobs are set to None before\n",
      "     |          pickling. See the remove_data method.\n",
      "     |          In some cases not all arrays will be set to None.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      If remove_data is true and the model result does not implement a\n",
      "     |      remove_data method then this will raise an exception.\n",
      "     |  \n",
      "     |  t_test(self, r_matrix, cov_p=None, scale=None, use_t=None)\n",
      "     |      Compute a t-test for a each linear hypothesis of the form Rb = q\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      r_matrix : array-like, str, tuple\n",
      "     |          - array : If an array is given, a p x k 2d array or length k 1d\n",
      "     |            array specifying the linear restrictions. It is assumed\n",
      "     |            that the linear combination is equal to zero.\n",
      "     |          - str : The full hypotheses to test can be given as a string.\n",
      "     |            See the examples.\n",
      "     |          - tuple : A tuple of arrays in the form (R, q). If q is given,\n",
      "     |            can be either a scalar or a length p row vector.\n",
      "     |      cov_p : array-like, optional\n",
      "     |          An alternative estimate for the parameter covariance matrix.\n",
      "     |          If None is given, self.normalized_cov_params is used.\n",
      "     |      scale : float, optional\n",
      "     |          An optional `scale` to use.  Default is the scale specified\n",
      "     |          by the model fit.\n",
      "     |      use_t : bool, optional\n",
      "     |          If use_t is None, then the default of the model is used.\n",
      "     |          If use_t is True, then the p-values are based on the t\n",
      "     |          distribution.\n",
      "     |          If use_t is False, then the p-values are based on the normal\n",
      "     |          distribution.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      res : ContrastResults instance\n",
      "     |          The results for the test are attributes of this results instance.\n",
      "     |          The available results have the same elements as the parameter table\n",
      "     |          in `summary()`.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import numpy as np\n",
      "     |      >>> import statsmodels.api as sm\n",
      "     |      >>> data = sm.datasets.longley.load()\n",
      "     |      >>> data.exog = sm.add_constant(data.exog)\n",
      "     |      >>> results = sm.OLS(data.endog, data.exog).fit()\n",
      "     |      >>> r = np.zeros_like(results.params)\n",
      "     |      >>> r[5:] = [1,-1]\n",
      "     |      >>> print(r)\n",
      "     |      [ 0.  0.  0.  0.  0.  1. -1.]\n",
      "     |      \n",
      "     |      r tests that the coefficients on the 5th and 6th independent\n",
      "     |      variable are the same.\n",
      "     |      \n",
      "     |      >>> T_test = results.t_test(r)\n",
      "     |      >>> print(T_test)\n",
      "     |                                   Test for Constraints\n",
      "     |      ==============================================================================\n",
      "     |                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "     |      ------------------------------------------------------------------------------\n",
      "     |      c0         -1829.2026    455.391     -4.017      0.003   -2859.368    -799.037\n",
      "     |      ==============================================================================\n",
      "     |      >>> T_test.effect\n",
      "     |      -1829.2025687192481\n",
      "     |      >>> T_test.sd\n",
      "     |      455.39079425193762\n",
      "     |      >>> T_test.tvalue\n",
      "     |      -4.0167754636411717\n",
      "     |      >>> T_test.pvalue\n",
      "     |      0.0015163772380899498\n",
      "     |      \n",
      "     |      Alternatively, you can specify the hypothesis tests using a string\n",
      "     |      \n",
      "     |      >>> from statsmodels.formula.api import ols\n",
      "     |      >>> dta = sm.datasets.longley.load_pandas().data\n",
      "     |      >>> formula = 'TOTEMP ~ GNPDEFL + GNP + UNEMP + ARMED + POP + YEAR'\n",
      "     |      >>> results = ols(formula, dta).fit()\n",
      "     |      >>> hypotheses = 'GNPDEFL = GNP, UNEMP = 2, YEAR/1829 = 1'\n",
      "     |      >>> t_test = results.t_test(hypotheses)\n",
      "     |      >>> print(t_test)\n",
      "     |                                   Test for Constraints\n",
      "     |      ==============================================================================\n",
      "     |                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "     |      ------------------------------------------------------------------------------\n",
      "     |      c0            15.0977     84.937      0.178      0.863    -177.042     207.238\n",
      "     |      c1            -2.0202      0.488     -8.231      0.000      -3.125      -0.915\n",
      "     |      c2             1.0001      0.249      0.000      1.000       0.437       1.563\n",
      "     |      ==============================================================================\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      ---------\n",
      "     |      tvalues : individual t statistics\n",
      "     |      f_test : for F tests\n",
      "     |      patsy.DesignInfo.linear_constraint\n",
      "     |  \n",
      "     |  t_test_pairwise(self, term_name, method='hs', alpha=0.05, factor_labels=None)\n",
      "     |      perform pairwise t_test with multiple testing corrected p-values\n",
      "     |      \n",
      "     |      This uses the formula design_info encoding contrast matrix and should\n",
      "     |      work for all encodings of a main effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      result : result instance\n",
      "     |          The results of an estimated model with a categorical main effect.\n",
      "     |      term_name : str\n",
      "     |          name of the term for which pairwise comparisons are computed.\n",
      "     |          Term names for categorical effects are created by patsy and\n",
      "     |          correspond to the main part of the exog names.\n",
      "     |      method : str or list of strings\n",
      "     |          multiple testing p-value correction, default is 'hs',\n",
      "     |          see stats.multipletesting\n",
      "     |      alpha : float\n",
      "     |          significance level for multiple testing reject decision.\n",
      "     |      factor_labels : None, list of str\n",
      "     |          Labels for the factor levels used for pairwise labels. If not\n",
      "     |          provided, then the labels from the formula design_info are used.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      results : instance of a simple Results class\n",
      "     |          The results are stored as attributes, the main attributes are the\n",
      "     |          following two. Other attributes are added for debugging purposes\n",
      "     |          or as background information.\n",
      "     |      \n",
      "     |          - result_frame : pandas DataFrame with t_test results and multiple\n",
      "     |            testing corrected p-values.\n",
      "     |          - contrasts : matrix of constraints of the null hypothesis in the\n",
      "     |            t_test.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Status: experimental. Currently only checked for treatment coding with\n",
      "     |      and without specified reference level.\n",
      "     |      \n",
      "     |      Currently there are no multiple testing corrected confidence intervals\n",
      "     |      available.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> res = ols(\"np.log(Days+1) ~ C(Weight) + C(Duration)\", data).fit()\n",
      "     |      >>> pw = res.t_test_pairwise(\"C(Weight)\")\n",
      "     |      >>> pw.result_frame\n",
      "     |               coef   std err         t         P>|t|  Conf. Int. Low\n",
      "     |      2-1  0.632315  0.230003  2.749157  8.028083e-03        0.171563\n",
      "     |      3-1  1.302555  0.230003  5.663201  5.331513e-07        0.841803\n",
      "     |      3-2  0.670240  0.230003  2.914044  5.119126e-03        0.209488\n",
      "     |           Conf. Int. Upp.  pvalue-hs reject-hs\n",
      "     |      2-1         1.093067   0.010212      True\n",
      "     |      3-1         1.763307   0.000002      True\n",
      "     |      3-2         1.130992   0.010212      True\n",
      "     |  \n",
      "     |  tvalues(self)\n",
      "     |      Return the t-statistic for a given parameter estimate.\n",
      "     |  \n",
      "     |  wald_test(self, r_matrix, cov_p=None, scale=1.0, invcov=None, use_f=None)\n",
      "     |      Compute a Wald-test for a joint linear hypothesis.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      r_matrix : array-like, str, or tuple\n",
      "     |          - array : An r x k array where r is the number of restrictions to\n",
      "     |            test and k is the number of regressors. It is assumed that the\n",
      "     |            linear combination is equal to zero.\n",
      "     |          - str : The full hypotheses to test can be given as a string.\n",
      "     |            See the examples.\n",
      "     |          - tuple : A tuple of arrays in the form (R, q), ``q`` can be\n",
      "     |            either a scalar or a length p row vector.\n",
      "     |      cov_p : array-like, optional\n",
      "     |          An alternative estimate for the parameter covariance matrix.\n",
      "     |          If None is given, self.normalized_cov_params is used.\n",
      "     |      scale : float, optional\n",
      "     |          Default is 1.0 for no scaling.\n",
      "     |      invcov : array-like, optional\n",
      "     |          A q x q array to specify an inverse covariance matrix based on a\n",
      "     |          restrictions matrix.\n",
      "     |      use_f : bool\n",
      "     |          If True, then the F-distribution is used. If False, then the\n",
      "     |          asymptotic distribution, chisquare is used. If use_f is None, then\n",
      "     |          the F distribution is used if the model specifies that use_t is True.\n",
      "     |          The test statistic is proportionally adjusted for the distribution\n",
      "     |          by the number of constraints in the hypothesis.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      res : ContrastResults instance\n",
      "     |          The results for the test are attributes of this results instance.\n",
      "     |      \n",
      "     |      See also\n",
      "     |      --------\n",
      "     |      statsmodels.stats.contrast.ContrastResults\n",
      "     |      f_test\n",
      "     |      t_test\n",
      "     |      patsy.DesignInfo.linear_constraint\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The matrix `r_matrix` is assumed to be non-singular. More precisely,\n",
      "     |      \n",
      "     |      r_matrix (pX pX.T) r_matrix.T\n",
      "     |      \n",
      "     |      is assumed invertible. Here, pX is the generalized inverse of the\n",
      "     |      design matrix of the model. There can be problems in non-OLS models\n",
      "     |      where the rank of the covariance of the noise is not full.\n",
      "     |  \n",
      "     |  wald_test_terms(self, skip_single=False, extra_constraints=None, combine_terms=None)\n",
      "     |      Compute a sequence of Wald tests for terms over multiple columns\n",
      "     |      \n",
      "     |      This computes joined Wald tests for the hypothesis that all\n",
      "     |      coefficients corresponding to a `term` are zero.\n",
      "     |      \n",
      "     |      `Terms` are defined by the underlying formula or by string matching.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      skip_single : boolean\n",
      "     |          If true, then terms that consist only of a single column and,\n",
      "     |          therefore, refers only to a single parameter is skipped.\n",
      "     |          If false, then all terms are included.\n",
      "     |      extra_constraints : ndarray\n",
      "     |          not tested yet\n",
      "     |      combine_terms : None or list of strings\n",
      "     |          Each string in this list is matched to the name of the terms or\n",
      "     |          the name of the exogenous variables. All columns whose name\n",
      "     |          includes that string are combined in one joint test.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      test_result : result instance\n",
      "     |          The result instance contains `table` which is a pandas DataFrame\n",
      "     |          with the test results: test statistic, degrees of freedom and\n",
      "     |          pvalues.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> res_ols = ols(\"np.log(Days+1) ~ C(Duration, Sum)*C(Weight, Sum)\", data).fit()\n",
      "     |      >>> res_ols.wald_test_terms()\n",
      "     |      <class 'statsmodels.stats.contrast.WaldTestResults'>\n",
      "     |                                                F                P>F  df constraint  df denom\n",
      "     |      Intercept                        279.754525  2.37985521351e-22              1        51\n",
      "     |      C(Duration, Sum)                   5.367071    0.0245738436636              1        51\n",
      "     |      C(Weight, Sum)                    12.432445  3.99943118767e-05              2        51\n",
      "     |      C(Duration, Sum):C(Weight, Sum)    0.176002      0.83912310946              2        51\n",
      "     |      \n",
      "     |      >>> res_poi = Poisson.from_formula(\"Days ~ C(Weight) * C(Duration)\",                                            data).fit(cov_type='HC0')\n",
      "     |      >>> wt = res_poi.wald_test_terms(skip_single=False,                                          combine_terms=['Duration', 'Weight'])\n",
      "     |      >>> print(wt)\n",
      "     |                                  chi2             P>chi2  df constraint\n",
      "     |      Intercept              15.695625  7.43960374424e-05              1\n",
      "     |      C(Weight)              16.132616  0.000313940174705              2\n",
      "     |      C(Duration)             1.009147     0.315107378931              1\n",
      "     |      C(Weight):C(Duration)   0.216694     0.897315972824              2\n",
      "     |      Duration               11.187849     0.010752286833              3\n",
      "     |      Weight                 30.263368  4.32586407145e-06              4\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  load(fname) from builtins.type\n",
      "     |      load a pickle, (class method)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname : string or filehandle\n",
      "     |          fname can be a string to a file path or filename, or a filehandle.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      unpickled instance\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  use_t = False\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Results:\n",
      "     |  \n",
      "     |  initialize(self, model, params, **kwd)\n",
      "     |  \n",
      "     |  predict(self, exog=None, transform=True, *args, **kwargs)\n",
      "     |      Call self.model.predict with self.params as the first argument.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      exog : array-like, optional\n",
      "     |          The values for which you want to predict. see Notes below.\n",
      "     |      transform : bool, optional\n",
      "     |          If the model was fit via a formula, do you want to pass\n",
      "     |          exog through the formula. Default is True. E.g., if you fit\n",
      "     |          a model y ~ log(x1) + log(x2), and transform is True, then\n",
      "     |          you can pass a data structure that contains x1 and x2 in\n",
      "     |          their original form. Otherwise, you'd need to log the data\n",
      "     |          first.\n",
      "     |      args, kwargs :\n",
      "     |          Some models can take additional arguments or keywords, see the\n",
      "     |          predict method of the model for the details.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      prediction : ndarray, pandas.Series or pandas.DataFrame\n",
      "     |          See self.model.predict\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The types of exog that are supported depends on whether a formula\n",
      "     |      was used in the specification of the model.\n",
      "     |      \n",
      "     |      If a formula was used, then exog is processed in the same way as\n",
      "     |      the original data. This transformation needs to have key access to the\n",
      "     |      same variable names, and can be a pandas DataFrame or a dict like\n",
      "     |      object.\n",
      "     |      \n",
      "     |      If no formula was used, then the provided exog needs to have the\n",
      "     |      same number of columns as the original exog in the model. No\n",
      "     |      transformation of the data is performed except converting it to\n",
      "     |      a numpy array.\n",
      "     |      \n",
      "     |      Row indices as in pandas data frames are supported, and added to the\n",
      "     |      returned prediction.\n",
      "     |  \n",
      "     |  summary(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Results:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class LikelihoodResultsWrapper(statsmodels.base.wrapper.ResultsWrapper)\n",
      "     |  LikelihoodResultsWrapper(results)\n",
      "     |  \n",
      "     |  Class which wraps a statsmodels estimation Results class and steps in to\n",
      "     |  reattach metadata to results (if available)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LikelihoodResultsWrapper\n",
      "     |      statsmodels.base.wrapper.ResultsWrapper\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  conf_int(self, alpha=0.05, cols=None, method='default')\n",
      "     |      conf_int(self, alpha=0.05, cols=None, method='default')\n",
      "     |      \n",
      "     |      Returns the confidence interval of the fitted parameters.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      alpha : float, optional\n",
      "     |          The significance level for the confidence interval.\n",
      "     |          ie., The default `alpha` = .05 returns a 95% confidence interval.\n",
      "     |      cols : array-like, optional\n",
      "     |          `cols` specifies which confidence intervals to return\n",
      "     |      method : string\n",
      "     |          Not Implemented Yet\n",
      "     |          Method to estimate the confidence_interval.\n",
      "     |          \"Default\" : uses self.bse which is based on inverse Hessian for MLE\n",
      "     |          \"hjjh\" :\n",
      "     |          \"jac\" :\n",
      "     |          \"boot-bse\"\n",
      "     |          \"boot_quant\"\n",
      "     |          \"profile\"\n",
      "     |      \n",
      "     |      \n",
      "     |      Returns\n",
      "     |      --------\n",
      "     |      conf_int : array\n",
      "     |          Each row contains [lower, upper] limits of the confidence interval\n",
      "     |          for the corresponding parameter. The first column contains all\n",
      "     |          lower, the second column contains all upper limits.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import statsmodels.api as sm\n",
      "     |      >>> data = sm.datasets.longley.load()\n",
      "     |      >>> data.exog = sm.add_constant(data.exog)\n",
      "     |      >>> results = sm.OLS(data.endog, data.exog).fit()\n",
      "     |      >>> results.conf_int()\n",
      "     |      array([[-5496529.48322745, -1467987.78596704],\n",
      "     |             [    -177.02903529,      207.15277984],\n",
      "     |             [      -0.1115811 ,        0.03994274],\n",
      "     |             [      -3.12506664,       -0.91539297],\n",
      "     |             [      -1.5179487 ,       -0.54850503],\n",
      "     |             [      -0.56251721,        0.460309  ],\n",
      "     |             [     798.7875153 ,     2859.51541392]])\n",
      "     |      \n",
      "     |      \n",
      "     |      >>> results.conf_int(cols=(2,3))\n",
      "     |      array([[-0.1115811 ,  0.03994274],\n",
      "     |             [-3.12506664, -0.91539297]])\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The confidence interval is based on the standard normal distribution.\n",
      "     |      Models wish to use a different distribution should overwrite this\n",
      "     |      method.\n",
      "     |  \n",
      "     |  cov_params(self, r_matrix=None, column=None, scale=None, cov_p=None, other=None)\n",
      "     |      cov_params(self, r_matrix=None, column=None, scale=None, cov_p=None, other=None)\n",
      "     |      \n",
      "     |      Returns the variance/covariance matrix.\n",
      "     |      \n",
      "     |      The variance/covariance matrix can be of a linear contrast\n",
      "     |      of the estimates of params or all params multiplied by scale which\n",
      "     |      will usually be an estimate of sigma^2.  Scale is assumed to be\n",
      "     |      a scalar.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      r_matrix : array-like\n",
      "     |          Can be 1d, or 2d.  Can be used alone or with other.\n",
      "     |      column :  array-like, optional\n",
      "     |          Must be used on its own.  Can be 0d or 1d see below.\n",
      "     |      scale : float, optional\n",
      "     |          Can be specified or not.  Default is None, which means that\n",
      "     |          the scale argument is taken from the model.\n",
      "     |      other : array-like, optional\n",
      "     |          Can be used when r_matrix is specified.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      cov : ndarray\n",
      "     |          covariance matrix of the parameter estimates or of linear\n",
      "     |          combination of parameter estimates. See Notes.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      (The below are assumed to be in matrix notation.)\n",
      "     |      \n",
      "     |      If no argument is specified returns the covariance matrix of a model\n",
      "     |      ``(scale)*(X.T X)^(-1)``\n",
      "     |      \n",
      "     |      If contrast is specified it pre and post-multiplies as follows\n",
      "     |      ``(scale) * r_matrix (X.T X)^(-1) r_matrix.T``\n",
      "     |      \n",
      "     |      If contrast and other are specified returns\n",
      "     |      ``(scale) * r_matrix (X.T X)^(-1) other.T``\n",
      "     |      \n",
      "     |      If column is specified returns\n",
      "     |      ``(scale) * (X.T X)^(-1)[column,column]`` if column is 0d\n",
      "     |      \n",
      "     |      OR\n",
      "     |      \n",
      "     |      ``(scale) * (X.T X)^(-1)[column][:,column]`` if column is 1d\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from statsmodels.base.wrapper.ResultsWrapper:\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      Default dir() implementation.\n",
      "     |  \n",
      "     |  __getattribute__(self, attr)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __init__(self, results)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __setstate__(self, dict_)\n",
      "     |  \n",
      "     |  save(self, fname, remove_data=False)\n",
      "     |      save a pickle of this instance\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname : string or filehandle\n",
      "     |          fname can be a string to a file path or filename, or a filehandle.\n",
      "     |      remove_data : bool\n",
      "     |          If False (default), then the instance is pickled without changes.\n",
      "     |          If True, then all arrays with length nobs are set to None before\n",
      "     |          pickling. See the remove_data method.\n",
      "     |          In some cases not all arrays will be set to None.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from statsmodels.base.wrapper.ResultsWrapper:\n",
      "     |  \n",
      "     |  load(fname) from builtins.type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from statsmodels.base.wrapper.ResultsWrapper:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Model(builtins.object)\n",
      "     |  Model(endog, exog=None, **kwargs)\n",
      "     |  \n",
      "     |  A (predictive) statistical model. Intended to be subclassed not used.\n",
      "     |  \n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  endog : array-like\n",
      "     |      1-d endogenous response variable. The dependent variable.\n",
      "     |  exog : array-like\n",
      "     |      A nobs x k array where `nobs` is the number of observations and `k`\n",
      "     |      is the number of regressors. An intercept is not included by default\n",
      "     |      and should be added by the user. See\n",
      "     |      :func:`statsmodels.tools.add_constant`.\n",
      "     |  missing : str\n",
      "     |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      "     |      checking is done. If 'drop', any observations with nans are dropped.\n",
      "     |      If 'raise', an error is raised. Default is 'none.'\n",
      "     |  hasconst : None or bool\n",
      "     |      Indicates whether the RHS includes a user-supplied constant. If True,\n",
      "     |      a constant is not checked for and k_constant is set to 1 and all\n",
      "     |      result statistics are calculated as if a constant is present. If\n",
      "     |      False, a constant is not checked for and k_constant is set to 0.\n",
      "     |  \n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  `endog` and `exog` are references to any data provided.  So if the data is\n",
      "     |  already stored in numpy arrays and it is changed then `endog` and `exog`\n",
      "     |  will change as well.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, endog, exog=None, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self)\n",
      "     |      Fit a model to data.\n",
      "     |  \n",
      "     |  predict(self, params, exog=None, *args, **kwargs)\n",
      "     |      After a model has been fit predict returns the fitted values.\n",
      "     |      \n",
      "     |      This is a placeholder intended to be overwritten by individual models.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      "     |      Create a Model from a formula and dataframe.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      formula : str or generic Formula object\n",
      "     |          The formula specifying the model\n",
      "     |      data : array-like\n",
      "     |          The data for the model. See Notes.\n",
      "     |      subset : array-like\n",
      "     |          An array-like object of booleans, integers, or index values that\n",
      "     |          indicate the subset of df to use in the model. Assumes df is a\n",
      "     |          `pandas.DataFrame`\n",
      "     |      drop_cols : array-like\n",
      "     |          Columns to drop from the design matrix.  Cannot be used to\n",
      "     |          drop terms involving categoricals.\n",
      "     |      args : extra arguments\n",
      "     |          These are passed to the model\n",
      "     |      kwargs : extra keyword arguments\n",
      "     |          These are passed to the model with one exception. The\n",
      "     |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      "     |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      "     |          indicating the depth of the namespace to use. For example, the\n",
      "     |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      "     |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model : Model instance\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      ------\n",
      "     |      data must define __getitem__ with the keys in the formula terms\n",
      "     |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      "     |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  endog_names\n",
      "     |      Names of endogenous variables\n",
      "     |  \n",
      "     |  exog_names\n",
      "     |      Names of exogenous variables\n",
      "    \n",
      "    class ResultMixin(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  aic(self)\n",
      "     |  \n",
      "     |  bic(self)\n",
      "     |  \n",
      "     |  bootstrap(self, nrep=100, method='nm', disp=0, store=1)\n",
      "     |      simple bootstrap to get mean and variance of estimator\n",
      "     |      \n",
      "     |      see notes\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      nrep : int\n",
      "     |          number of bootstrap replications\n",
      "     |      method : str\n",
      "     |          optimization method to use\n",
      "     |      disp : bool\n",
      "     |          If true, then optimization prints results\n",
      "     |      store : bool\n",
      "     |          If true, then parameter estimates for all bootstrap iterations\n",
      "     |          are attached in self.bootstrap_results\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      mean : array\n",
      "     |          mean of parameter estimates over bootstrap replications\n",
      "     |      std : array\n",
      "     |          standard deviation of parameter estimates over bootstrap\n",
      "     |          replications\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This was mainly written to compare estimators of the standard errors of\n",
      "     |      the parameter estimates.  It uses independent random sampling from the\n",
      "     |      original endog and exog, and therefore is only correct if observations\n",
      "     |      are independently distributed.\n",
      "     |      \n",
      "     |      This will be moved to apply only to models with independently\n",
      "     |      distributed observations.\n",
      "     |  \n",
      "     |  bsejac(self)\n",
      "     |      standard deviation of parameter estimates based on covjac\n",
      "     |  \n",
      "     |  bsejhj(self)\n",
      "     |      standard deviation of parameter estimates based on covHJH\n",
      "     |  \n",
      "     |  covjac(self)\n",
      "     |      covariance of parameters based on outer product of jacobian of\n",
      "     |      log-likelihood\n",
      "     |  \n",
      "     |  covjhj(self)\n",
      "     |      covariance of parameters based on HJJH\n",
      "     |      \n",
      "     |      dot product of Hessian, Jacobian, Jacobian, Hessian of likelihood\n",
      "     |      \n",
      "     |      name should be covhjh\n",
      "     |  \n",
      "     |  df_modelwc(self)\n",
      "     |  \n",
      "     |  get_nlfun(self, fun)\n",
      "     |  \n",
      "     |  hessv(self)\n",
      "     |      cached Hessian of log-likelihood\n",
      "     |  \n",
      "     |  score_obsv(self)\n",
      "     |      cached Jacobian of log-likelihood\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Results(builtins.object)\n",
      "     |  Results(model, params, **kwd)\n",
      "     |  \n",
      "     |  Class to contain model results\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  model : class instance\n",
      "     |      the previously specified model instance\n",
      "     |  params : array\n",
      "     |      parameter estimates from the fit model\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, model, params, **kwd)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  initialize(self, model, params, **kwd)\n",
      "     |  \n",
      "     |  predict(self, exog=None, transform=True, *args, **kwargs)\n",
      "     |      Call self.model.predict with self.params as the first argument.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      exog : array-like, optional\n",
      "     |          The values for which you want to predict. see Notes below.\n",
      "     |      transform : bool, optional\n",
      "     |          If the model was fit via a formula, do you want to pass\n",
      "     |          exog through the formula. Default is True. E.g., if you fit\n",
      "     |          a model y ~ log(x1) + log(x2), and transform is True, then\n",
      "     |          you can pass a data structure that contains x1 and x2 in\n",
      "     |          their original form. Otherwise, you'd need to log the data\n",
      "     |          first.\n",
      "     |      args, kwargs :\n",
      "     |          Some models can take additional arguments or keywords, see the\n",
      "     |          predict method of the model for the details.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      prediction : ndarray, pandas.Series or pandas.DataFrame\n",
      "     |          See self.model.predict\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The types of exog that are supported depends on whether a formula\n",
      "     |      was used in the specification of the model.\n",
      "     |      \n",
      "     |      If a formula was used, then exog is processed in the same way as\n",
      "     |      the original data. This transformation needs to have key access to the\n",
      "     |      same variable names, and can be a pandas DataFrame or a dict like\n",
      "     |      object.\n",
      "     |      \n",
      "     |      If no formula was used, then the provided exog needs to have the\n",
      "     |      same number of columns as the original exog in the model. No\n",
      "     |      transformation of the data is performed except converting it to\n",
      "     |      a numpy array.\n",
      "     |      \n",
      "     |      Row indices as in pandas data frames are supported, and added to the\n",
      "     |      returned prediction.\n",
      "     |  \n",
      "     |  summary(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    reduce(...)\n",
      "        reduce(function, sequence[, initial]) -> value\n",
      "        \n",
      "        Apply a function of two arguments cumulatively to the items of a sequence,\n",
      "        from left to right, so as to reduce the sequence to a single value.\n",
      "        For example, reduce(lambda x, y: x+y, [1, 2, 3, 4, 5]) calculates\n",
      "        ((((1+2)+3)+4)+5).  If initial is present, it is placed before the items\n",
      "        of the sequence in the calculation, and serves as a default when the\n",
      "        sequence is empty.\n",
      "\n",
      "DATA\n",
      "    cache_readonly = <statsmodels.tools.decorators._cache_readonly object>\n",
      "    print_function = _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0)...\n",
      "\n",
      "FILE\n",
      "    c:\\users\\lenovo\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Model in module statsmodels.base.model:\n",
      "\n",
      "class Model(builtins.object)\n",
      " |  Model(endog, exog=None, **kwargs)\n",
      " |  \n",
      " |  A (predictive) statistical model. Intended to be subclassed not used.\n",
      " |  \n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  endog : array-like\n",
      " |      1-d endogenous response variable. The dependent variable.\n",
      " |  exog : array-like\n",
      " |      A nobs x k array where `nobs` is the number of observations and `k`\n",
      " |      is the number of regressors. An intercept is not included by default\n",
      " |      and should be added by the user. See\n",
      " |      :func:`statsmodels.tools.add_constant`.\n",
      " |  missing : str\n",
      " |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      " |      checking is done. If 'drop', any observations with nans are dropped.\n",
      " |      If 'raise', an error is raised. Default is 'none.'\n",
      " |  hasconst : None or bool\n",
      " |      Indicates whether the RHS includes a user-supplied constant. If True,\n",
      " |      a constant is not checked for and k_constant is set to 1 and all\n",
      " |      result statistics are calculated as if a constant is present. If\n",
      " |      False, a constant is not checked for and k_constant is set to 0.\n",
      " |  \n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  `endog` and `exog` are references to any data provided.  So if the data is\n",
      " |  already stored in numpy arrays and it is changed then `endog` and `exog`\n",
      " |  will change as well.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, endog, exog=None, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self)\n",
      " |      Fit a model to data.\n",
      " |  \n",
      " |  predict(self, params, exog=None, *args, **kwargs)\n",
      " |      After a model has been fit predict returns the fitted values.\n",
      " |      \n",
      " |      This is a placeholder intended to be overwritten by individual models.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      " |      Create a Model from a formula and dataframe.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      formula : str or generic Formula object\n",
      " |          The formula specifying the model\n",
      " |      data : array-like\n",
      " |          The data for the model. See Notes.\n",
      " |      subset : array-like\n",
      " |          An array-like object of booleans, integers, or index values that\n",
      " |          indicate the subset of df to use in the model. Assumes df is a\n",
      " |          `pandas.DataFrame`\n",
      " |      drop_cols : array-like\n",
      " |          Columns to drop from the design matrix.  Cannot be used to\n",
      " |          drop terms involving categoricals.\n",
      " |      args : extra arguments\n",
      " |          These are passed to the model\n",
      " |      kwargs : extra keyword arguments\n",
      " |          These are passed to the model with one exception. The\n",
      " |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      " |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      " |          indicating the depth of the namespace to use. For example, the\n",
      " |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      " |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      model : Model instance\n",
      " |      \n",
      " |      Notes\n",
      " |      ------\n",
      " |      data must define __getitem__ with the keys in the formula terms\n",
      " |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      " |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  endog_names\n",
      " |      Names of endogenous variables\n",
      " |  \n",
      " |  exog_names\n",
      " |      Names of exogenous variables\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model.Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LikelihoodModelResults in module statsmodels.base.model:\n",
      "\n",
      "class LikelihoodModelResults(Results)\n",
      " |  LikelihoodModelResults(model, params, normalized_cov_params=None, scale=1.0, **kwargs)\n",
      " |  \n",
      " |  Class to contain results from likelihood models\n",
      " |  \n",
      " |  Parameters\n",
      " |  -----------\n",
      " |  model : LikelihoodModel instance or subclass instance\n",
      " |      LikelihoodModelResults holds a reference to the model that is fit.\n",
      " |  params : 1d array_like\n",
      " |      parameter estimates from estimated model\n",
      " |  normalized_cov_params : 2d array\n",
      " |     Normalized (before scaling) covariance of params. (dot(X.T,X))**-1\n",
      " |  scale : float\n",
      " |      For (some subset of models) scale will typically be the\n",
      " |      mean square error from the estimated model (sigma^2)\n",
      " |  \n",
      " |  Returns\n",
      " |  -------\n",
      " |  **Attributes**\n",
      " |  mle_retvals : dict\n",
      " |      Contains the values returned from the chosen optimization method if\n",
      " |      full_output is True during the fit.  Available only if the model\n",
      " |      is fit by maximum likelihood.  See notes below for the output from\n",
      " |      the different methods.\n",
      " |  mle_settings : dict\n",
      " |      Contains the arguments passed to the chosen optimization method.\n",
      " |      Available if the model is fit by maximum likelihood.  See\n",
      " |      LikelihoodModel.fit for more information.\n",
      " |  model : model instance\n",
      " |      LikelihoodResults contains a reference to the model that is fit.\n",
      " |  params : ndarray\n",
      " |      The parameters estimated for the model.\n",
      " |  scale : float\n",
      " |      The scaling factor of the model given during instantiation.\n",
      " |  tvalues : array\n",
      " |      The t-values of the standard errors.\n",
      " |  \n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The covariance of params is given by scale times normalized_cov_params.\n",
      " |  \n",
      " |  Return values by solver if full_output is True during fit:\n",
      " |  \n",
      " |      'newton'\n",
      " |          fopt : float\n",
      " |              The value of the (negative) loglikelihood at its\n",
      " |              minimum.\n",
      " |          iterations : int\n",
      " |              Number of iterations performed.\n",
      " |          score : ndarray\n",
      " |              The score vector at the optimum.\n",
      " |          Hessian : ndarray\n",
      " |              The Hessian at the optimum.\n",
      " |          warnflag : int\n",
      " |              1 if maxiter is exceeded. 0 if successful convergence.\n",
      " |          converged : bool\n",
      " |              True: converged. False: did not converge.\n",
      " |          allvecs : list\n",
      " |              List of solutions at each iteration.\n",
      " |      'nm'\n",
      " |          fopt : float\n",
      " |              The value of the (negative) loglikelihood at its\n",
      " |              minimum.\n",
      " |          iterations : int\n",
      " |              Number of iterations performed.\n",
      " |          warnflag : int\n",
      " |              1: Maximum number of function evaluations made.\n",
      " |              2: Maximum number of iterations reached.\n",
      " |          converged : bool\n",
      " |              True: converged. False: did not converge.\n",
      " |          allvecs : list\n",
      " |              List of solutions at each iteration.\n",
      " |      'bfgs'\n",
      " |          fopt : float\n",
      " |              Value of the (negative) loglikelihood at its minimum.\n",
      " |          gopt : float\n",
      " |              Value of gradient at minimum, which should be near 0.\n",
      " |          Hinv : ndarray\n",
      " |              value of the inverse Hessian matrix at minimum.  Note\n",
      " |              that this is just an approximation and will often be\n",
      " |              different from the value of the analytic Hessian.\n",
      " |          fcalls : int\n",
      " |              Number of calls to loglike.\n",
      " |          gcalls : int\n",
      " |              Number of calls to gradient/score.\n",
      " |          warnflag : int\n",
      " |              1: Maximum number of iterations exceeded. 2: Gradient\n",
      " |              and/or function calls are not changing.\n",
      " |          converged : bool\n",
      " |              True: converged.  False: did not converge.\n",
      " |          allvecs : list\n",
      " |              Results at each iteration.\n",
      " |      'lbfgs'\n",
      " |          fopt : float\n",
      " |              Value of the (negative) loglikelihood at its minimum.\n",
      " |          gopt : float\n",
      " |              Value of gradient at minimum, which should be near 0.\n",
      " |          fcalls : int\n",
      " |              Number of calls to loglike.\n",
      " |          warnflag : int\n",
      " |              Warning flag:\n",
      " |  \n",
      " |              - 0 if converged\n",
      " |              - 1 if too many function evaluations or too many iterations\n",
      " |              - 2 if stopped for another reason\n",
      " |  \n",
      " |          converged : bool\n",
      " |              True: converged.  False: did not converge.\n",
      " |      'powell'\n",
      " |          fopt : float\n",
      " |              Value of the (negative) loglikelihood at its minimum.\n",
      " |          direc : ndarray\n",
      " |              Current direction set.\n",
      " |          iterations : int\n",
      " |              Number of iterations performed.\n",
      " |          fcalls : int\n",
      " |              Number of calls to loglike.\n",
      " |          warnflag : int\n",
      " |              1: Maximum number of function evaluations. 2: Maximum number\n",
      " |              of iterations.\n",
      " |          converged : bool\n",
      " |              True : converged. False: did not converge.\n",
      " |          allvecs : list\n",
      " |              Results at each iteration.\n",
      " |      'cg'\n",
      " |          fopt : float\n",
      " |              Value of the (negative) loglikelihood at its minimum.\n",
      " |          fcalls : int\n",
      " |              Number of calls to loglike.\n",
      " |          gcalls : int\n",
      " |              Number of calls to gradient/score.\n",
      " |          warnflag : int\n",
      " |              1: Maximum number of iterations exceeded. 2: Gradient and/\n",
      " |              or function calls not changing.\n",
      " |          converged : bool\n",
      " |              True: converged. False: did not converge.\n",
      " |          allvecs : list\n",
      " |              Results at each iteration.\n",
      " |      'ncg'\n",
      " |          fopt : float\n",
      " |              Value of the (negative) loglikelihood at its minimum.\n",
      " |          fcalls : int\n",
      " |              Number of calls to loglike.\n",
      " |          gcalls : int\n",
      " |              Number of calls to gradient/score.\n",
      " |          hcalls : int\n",
      " |              Number of calls to hessian.\n",
      " |          warnflag : int\n",
      " |              1: Maximum number of iterations exceeded.\n",
      " |          converged : bool\n",
      " |              True: converged. False: did not converge.\n",
      " |          allvecs : list\n",
      " |              Results at each iteration.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LikelihoodModelResults\n",
      " |      Results\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, model, params, normalized_cov_params=None, scale=1.0, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  bse(self)\n",
      " |  \n",
      " |  conf_int(self, alpha=0.05, cols=None, method='default')\n",
      " |      Returns the confidence interval of the fitted parameters.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      alpha : float, optional\n",
      " |          The significance level for the confidence interval.\n",
      " |          ie., The default `alpha` = .05 returns a 95% confidence interval.\n",
      " |      cols : array-like, optional\n",
      " |          `cols` specifies which confidence intervals to return\n",
      " |      method : string\n",
      " |          Not Implemented Yet\n",
      " |          Method to estimate the confidence_interval.\n",
      " |          \"Default\" : uses self.bse which is based on inverse Hessian for MLE\n",
      " |          \"hjjh\" :\n",
      " |          \"jac\" :\n",
      " |          \"boot-bse\"\n",
      " |          \"boot_quant\"\n",
      " |          \"profile\"\n",
      " |      \n",
      " |      \n",
      " |      Returns\n",
      " |      --------\n",
      " |      conf_int : array\n",
      " |          Each row contains [lower, upper] limits of the confidence interval\n",
      " |          for the corresponding parameter. The first column contains all\n",
      " |          lower, the second column contains all upper limits.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import statsmodels.api as sm\n",
      " |      >>> data = sm.datasets.longley.load()\n",
      " |      >>> data.exog = sm.add_constant(data.exog)\n",
      " |      >>> results = sm.OLS(data.endog, data.exog).fit()\n",
      " |      >>> results.conf_int()\n",
      " |      array([[-5496529.48322745, -1467987.78596704],\n",
      " |             [    -177.02903529,      207.15277984],\n",
      " |             [      -0.1115811 ,        0.03994274],\n",
      " |             [      -3.12506664,       -0.91539297],\n",
      " |             [      -1.5179487 ,       -0.54850503],\n",
      " |             [      -0.56251721,        0.460309  ],\n",
      " |             [     798.7875153 ,     2859.51541392]])\n",
      " |      \n",
      " |      \n",
      " |      >>> results.conf_int(cols=(2,3))\n",
      " |      array([[-0.1115811 ,  0.03994274],\n",
      " |             [-3.12506664, -0.91539297]])\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The confidence interval is based on the standard normal distribution.\n",
      " |      Models wish to use a different distribution should overwrite this\n",
      " |      method.\n",
      " |  \n",
      " |  cov_params(self, r_matrix=None, column=None, scale=None, cov_p=None, other=None)\n",
      " |      Returns the variance/covariance matrix.\n",
      " |      \n",
      " |      The variance/covariance matrix can be of a linear contrast\n",
      " |      of the estimates of params or all params multiplied by scale which\n",
      " |      will usually be an estimate of sigma^2.  Scale is assumed to be\n",
      " |      a scalar.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      r_matrix : array-like\n",
      " |          Can be 1d, or 2d.  Can be used alone or with other.\n",
      " |      column :  array-like, optional\n",
      " |          Must be used on its own.  Can be 0d or 1d see below.\n",
      " |      scale : float, optional\n",
      " |          Can be specified or not.  Default is None, which means that\n",
      " |          the scale argument is taken from the model.\n",
      " |      other : array-like, optional\n",
      " |          Can be used when r_matrix is specified.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cov : ndarray\n",
      " |          covariance matrix of the parameter estimates or of linear\n",
      " |          combination of parameter estimates. See Notes.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      (The below are assumed to be in matrix notation.)\n",
      " |      \n",
      " |      If no argument is specified returns the covariance matrix of a model\n",
      " |      ``(scale)*(X.T X)^(-1)``\n",
      " |      \n",
      " |      If contrast is specified it pre and post-multiplies as follows\n",
      " |      ``(scale) * r_matrix (X.T X)^(-1) r_matrix.T``\n",
      " |      \n",
      " |      If contrast and other are specified returns\n",
      " |      ``(scale) * r_matrix (X.T X)^(-1) other.T``\n",
      " |      \n",
      " |      If column is specified returns\n",
      " |      ``(scale) * (X.T X)^(-1)[column,column]`` if column is 0d\n",
      " |      \n",
      " |      OR\n",
      " |      \n",
      " |      ``(scale) * (X.T X)^(-1)[column][:,column]`` if column is 1d\n",
      " |  \n",
      " |  f_test(self, r_matrix, cov_p=None, scale=1.0, invcov=None)\n",
      " |      Compute the F-test for a joint linear hypothesis.\n",
      " |      \n",
      " |      This is a special case of `wald_test` that always uses the F\n",
      " |      distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      r_matrix : array-like, str, or tuple\n",
      " |          - array : An r x k array where r is the number of restrictions to\n",
      " |            test and k is the number of regressors. It is assumed\n",
      " |            that the linear combination is equal to zero.\n",
      " |          - str : The full hypotheses to test can be given as a string.\n",
      " |            See the examples.\n",
      " |          - tuple : A tuple of arrays in the form (R, q), ``q`` can be\n",
      " |            either a scalar or a length k row vector.\n",
      " |      cov_p : array-like, optional\n",
      " |          An alternative estimate for the parameter covariance matrix.\n",
      " |          If None is given, self.normalized_cov_params is used.\n",
      " |      scale : float, optional\n",
      " |          Default is 1.0 for no scaling.\n",
      " |      invcov : array-like, optional\n",
      " |          A q x q array to specify an inverse covariance matrix based on a\n",
      " |          restrictions matrix.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      res : ContrastResults instance\n",
      " |          The results for the test are attributes of this results instance.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import numpy as np\n",
      " |      >>> import statsmodels.api as sm\n",
      " |      >>> data = sm.datasets.longley.load()\n",
      " |      >>> data.exog = sm.add_constant(data.exog)\n",
      " |      >>> results = sm.OLS(data.endog, data.exog).fit()\n",
      " |      >>> A = np.identity(len(results.params))\n",
      " |      >>> A = A[1:,:]\n",
      " |      \n",
      " |      This tests that each coefficient is jointly statistically\n",
      " |      significantly different from zero.\n",
      " |      \n",
      " |      >>> print(results.f_test(A))\n",
      " |      <F test: F=array([[ 330.28533923]]), p=4.984030528700946e-10, df_denom=9, df_num=6>\n",
      " |      \n",
      " |      Compare this to\n",
      " |      \n",
      " |      >>> results.fvalue\n",
      " |      330.2853392346658\n",
      " |      >>> results.f_pvalue\n",
      " |      4.98403096572e-10\n",
      " |      \n",
      " |      >>> B = np.array(([0,0,1,-1,0,0,0],[0,0,0,0,0,1,-1]))\n",
      " |      \n",
      " |      This tests that the coefficient on the 2nd and 3rd regressors are\n",
      " |      equal and jointly that the coefficient on the 5th and 6th regressors\n",
      " |      are equal.\n",
      " |      \n",
      " |      >>> print(results.f_test(B))\n",
      " |      <F test: F=array([[ 9.74046187]]), p=0.005605288531708235, df_denom=9, df_num=2>\n",
      " |      \n",
      " |      Alternatively, you can specify the hypothesis tests using a string\n",
      " |      \n",
      " |      >>> from statsmodels.datasets import longley\n",
      " |      >>> from statsmodels.formula.api import ols\n",
      " |      >>> dta = longley.load_pandas().data\n",
      " |      >>> formula = 'TOTEMP ~ GNPDEFL + GNP + UNEMP + ARMED + POP + YEAR'\n",
      " |      >>> results = ols(formula, dta).fit()\n",
      " |      >>> hypotheses = '(GNPDEFL = GNP), (UNEMP = 2), (YEAR/1829 = 1)'\n",
      " |      >>> f_test = results.f_test(hypotheses)\n",
      " |      >>> print(f_test)\n",
      " |      <F test: F=array([[ 144.17976065]]), p=6.322026217355609e-08, df_denom=9, df_num=3>\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      statsmodels.stats.contrast.ContrastResults\n",
      " |      wald_test\n",
      " |      t_test\n",
      " |      patsy.DesignInfo.linear_constraint\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The matrix `r_matrix` is assumed to be non-singular. More precisely,\n",
      " |      \n",
      " |      r_matrix (pX pX.T) r_matrix.T\n",
      " |      \n",
      " |      is assumed invertible. Here, pX is the generalized inverse of the\n",
      " |      design matrix of the model. There can be problems in non-OLS models\n",
      " |      where the rank of the covariance of the noise is not full.\n",
      " |  \n",
      " |  llf(self)\n",
      " |  \n",
      " |  normalized_cov_params(self)\n",
      " |  \n",
      " |  pvalues(self)\n",
      " |  \n",
      " |  remove_data(self)\n",
      " |      remove data arrays, all nobs arrays from result and model\n",
      " |      \n",
      " |      This reduces the size of the instance, so it can be pickled with less\n",
      " |      memory. Currently tested for use with predict from an unpickled\n",
      " |      results and model instance.\n",
      " |      \n",
      " |      .. warning:: Since data and some intermediate results have been removed\n",
      " |         calculating new statistics that require them will raise exceptions.\n",
      " |         The exception will occur the first time an attribute is accessed\n",
      " |         that has been set to None.\n",
      " |      \n",
      " |      Not fully tested for time series models, tsa, and might delete too much\n",
      " |      for prediction or not all that would be possible.\n",
      " |      \n",
      " |      The lists of arrays to delete are maintained as attributes of\n",
      " |      the result and model instance, except for cached values. These\n",
      " |      lists could be changed before calling remove_data.\n",
      " |      \n",
      " |      The attributes to remove are named in:\n",
      " |      \n",
      " |      model._data_attr : arrays attached to both the model instance\n",
      " |          and the results instance with the same attribute name.\n",
      " |      \n",
      " |      result.data_in_cache : arrays that may exist as values in\n",
      " |          result._cache (TODO : should privatize name)\n",
      " |      \n",
      " |      result._data_attr_model : arrays attached to the model\n",
      " |          instance but not to the results instance\n",
      " |  \n",
      " |  save(self, fname, remove_data=False)\n",
      " |      save a pickle of this instance\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : string or filehandle\n",
      " |          fname can be a string to a file path or filename, or a filehandle.\n",
      " |      remove_data : bool\n",
      " |          If False (default), then the instance is pickled without changes.\n",
      " |          If True, then all arrays with length nobs are set to None before\n",
      " |          pickling. See the remove_data method.\n",
      " |          In some cases not all arrays will be set to None.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If remove_data is true and the model result does not implement a\n",
      " |      remove_data method then this will raise an exception.\n",
      " |  \n",
      " |  t_test(self, r_matrix, cov_p=None, scale=None, use_t=None)\n",
      " |      Compute a t-test for a each linear hypothesis of the form Rb = q\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      r_matrix : array-like, str, tuple\n",
      " |          - array : If an array is given, a p x k 2d array or length k 1d\n",
      " |            array specifying the linear restrictions. It is assumed\n",
      " |            that the linear combination is equal to zero.\n",
      " |          - str : The full hypotheses to test can be given as a string.\n",
      " |            See the examples.\n",
      " |          - tuple : A tuple of arrays in the form (R, q). If q is given,\n",
      " |            can be either a scalar or a length p row vector.\n",
      " |      cov_p : array-like, optional\n",
      " |          An alternative estimate for the parameter covariance matrix.\n",
      " |          If None is given, self.normalized_cov_params is used.\n",
      " |      scale : float, optional\n",
      " |          An optional `scale` to use.  Default is the scale specified\n",
      " |          by the model fit.\n",
      " |      use_t : bool, optional\n",
      " |          If use_t is None, then the default of the model is used.\n",
      " |          If use_t is True, then the p-values are based on the t\n",
      " |          distribution.\n",
      " |          If use_t is False, then the p-values are based on the normal\n",
      " |          distribution.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      res : ContrastResults instance\n",
      " |          The results for the test are attributes of this results instance.\n",
      " |          The available results have the same elements as the parameter table\n",
      " |          in `summary()`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import numpy as np\n",
      " |      >>> import statsmodels.api as sm\n",
      " |      >>> data = sm.datasets.longley.load()\n",
      " |      >>> data.exog = sm.add_constant(data.exog)\n",
      " |      >>> results = sm.OLS(data.endog, data.exog).fit()\n",
      " |      >>> r = np.zeros_like(results.params)\n",
      " |      >>> r[5:] = [1,-1]\n",
      " |      >>> print(r)\n",
      " |      [ 0.  0.  0.  0.  0.  1. -1.]\n",
      " |      \n",
      " |      r tests that the coefficients on the 5th and 6th independent\n",
      " |      variable are the same.\n",
      " |      \n",
      " |      >>> T_test = results.t_test(r)\n",
      " |      >>> print(T_test)\n",
      " |                                   Test for Constraints\n",
      " |      ==============================================================================\n",
      " |                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      " |      ------------------------------------------------------------------------------\n",
      " |      c0         -1829.2026    455.391     -4.017      0.003   -2859.368    -799.037\n",
      " |      ==============================================================================\n",
      " |      >>> T_test.effect\n",
      " |      -1829.2025687192481\n",
      " |      >>> T_test.sd\n",
      " |      455.39079425193762\n",
      " |      >>> T_test.tvalue\n",
      " |      -4.0167754636411717\n",
      " |      >>> T_test.pvalue\n",
      " |      0.0015163772380899498\n",
      " |      \n",
      " |      Alternatively, you can specify the hypothesis tests using a string\n",
      " |      \n",
      " |      >>> from statsmodels.formula.api import ols\n",
      " |      >>> dta = sm.datasets.longley.load_pandas().data\n",
      " |      >>> formula = 'TOTEMP ~ GNPDEFL + GNP + UNEMP + ARMED + POP + YEAR'\n",
      " |      >>> results = ols(formula, dta).fit()\n",
      " |      >>> hypotheses = 'GNPDEFL = GNP, UNEMP = 2, YEAR/1829 = 1'\n",
      " |      >>> t_test = results.t_test(hypotheses)\n",
      " |      >>> print(t_test)\n",
      " |                                   Test for Constraints\n",
      " |      ==============================================================================\n",
      " |                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      " |      ------------------------------------------------------------------------------\n",
      " |      c0            15.0977     84.937      0.178      0.863    -177.042     207.238\n",
      " |      c1            -2.0202      0.488     -8.231      0.000      -3.125      -0.915\n",
      " |      c2             1.0001      0.249      0.000      1.000       0.437       1.563\n",
      " |      ==============================================================================\n",
      " |      \n",
      " |      See Also\n",
      " |      ---------\n",
      " |      tvalues : individual t statistics\n",
      " |      f_test : for F tests\n",
      " |      patsy.DesignInfo.linear_constraint\n",
      " |  \n",
      " |  t_test_pairwise(self, term_name, method='hs', alpha=0.05, factor_labels=None)\n",
      " |      perform pairwise t_test with multiple testing corrected p-values\n",
      " |      \n",
      " |      This uses the formula design_info encoding contrast matrix and should\n",
      " |      work for all encodings of a main effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      result : result instance\n",
      " |          The results of an estimated model with a categorical main effect.\n",
      " |      term_name : str\n",
      " |          name of the term for which pairwise comparisons are computed.\n",
      " |          Term names for categorical effects are created by patsy and\n",
      " |          correspond to the main part of the exog names.\n",
      " |      method : str or list of strings\n",
      " |          multiple testing p-value correction, default is 'hs',\n",
      " |          see stats.multipletesting\n",
      " |      alpha : float\n",
      " |          significance level for multiple testing reject decision.\n",
      " |      factor_labels : None, list of str\n",
      " |          Labels for the factor levels used for pairwise labels. If not\n",
      " |          provided, then the labels from the formula design_info are used.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      results : instance of a simple Results class\n",
      " |          The results are stored as attributes, the main attributes are the\n",
      " |          following two. Other attributes are added for debugging purposes\n",
      " |          or as background information.\n",
      " |      \n",
      " |          - result_frame : pandas DataFrame with t_test results and multiple\n",
      " |            testing corrected p-values.\n",
      " |          - contrasts : matrix of constraints of the null hypothesis in the\n",
      " |            t_test.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Status: experimental. Currently only checked for treatment coding with\n",
      " |      and without specified reference level.\n",
      " |      \n",
      " |      Currently there are no multiple testing corrected confidence intervals\n",
      " |      available.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> res = ols(\"np.log(Days+1) ~ C(Weight) + C(Duration)\", data).fit()\n",
      " |      >>> pw = res.t_test_pairwise(\"C(Weight)\")\n",
      " |      >>> pw.result_frame\n",
      " |               coef   std err         t         P>|t|  Conf. Int. Low\n",
      " |      2-1  0.632315  0.230003  2.749157  8.028083e-03        0.171563\n",
      " |      3-1  1.302555  0.230003  5.663201  5.331513e-07        0.841803\n",
      " |      3-2  0.670240  0.230003  2.914044  5.119126e-03        0.209488\n",
      " |           Conf. Int. Upp.  pvalue-hs reject-hs\n",
      " |      2-1         1.093067   0.010212      True\n",
      " |      3-1         1.763307   0.000002      True\n",
      " |      3-2         1.130992   0.010212      True\n",
      " |  \n",
      " |  tvalues(self)\n",
      " |      Return the t-statistic for a given parameter estimate.\n",
      " |  \n",
      " |  wald_test(self, r_matrix, cov_p=None, scale=1.0, invcov=None, use_f=None)\n",
      " |      Compute a Wald-test for a joint linear hypothesis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      r_matrix : array-like, str, or tuple\n",
      " |          - array : An r x k array where r is the number of restrictions to\n",
      " |            test and k is the number of regressors. It is assumed that the\n",
      " |            linear combination is equal to zero.\n",
      " |          - str : The full hypotheses to test can be given as a string.\n",
      " |            See the examples.\n",
      " |          - tuple : A tuple of arrays in the form (R, q), ``q`` can be\n",
      " |            either a scalar or a length p row vector.\n",
      " |      cov_p : array-like, optional\n",
      " |          An alternative estimate for the parameter covariance matrix.\n",
      " |          If None is given, self.normalized_cov_params is used.\n",
      " |      scale : float, optional\n",
      " |          Default is 1.0 for no scaling.\n",
      " |      invcov : array-like, optional\n",
      " |          A q x q array to specify an inverse covariance matrix based on a\n",
      " |          restrictions matrix.\n",
      " |      use_f : bool\n",
      " |          If True, then the F-distribution is used. If False, then the\n",
      " |          asymptotic distribution, chisquare is used. If use_f is None, then\n",
      " |          the F distribution is used if the model specifies that use_t is True.\n",
      " |          The test statistic is proportionally adjusted for the distribution\n",
      " |          by the number of constraints in the hypothesis.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      res : ContrastResults instance\n",
      " |          The results for the test are attributes of this results instance.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      statsmodels.stats.contrast.ContrastResults\n",
      " |      f_test\n",
      " |      t_test\n",
      " |      patsy.DesignInfo.linear_constraint\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The matrix `r_matrix` is assumed to be non-singular. More precisely,\n",
      " |      \n",
      " |      r_matrix (pX pX.T) r_matrix.T\n",
      " |      \n",
      " |      is assumed invertible. Here, pX is the generalized inverse of the\n",
      " |      design matrix of the model. There can be problems in non-OLS models\n",
      " |      where the rank of the covariance of the noise is not full.\n",
      " |  \n",
      " |  wald_test_terms(self, skip_single=False, extra_constraints=None, combine_terms=None)\n",
      " |      Compute a sequence of Wald tests for terms over multiple columns\n",
      " |      \n",
      " |      This computes joined Wald tests for the hypothesis that all\n",
      " |      coefficients corresponding to a `term` are zero.\n",
      " |      \n",
      " |      `Terms` are defined by the underlying formula or by string matching.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skip_single : boolean\n",
      " |          If true, then terms that consist only of a single column and,\n",
      " |          therefore, refers only to a single parameter is skipped.\n",
      " |          If false, then all terms are included.\n",
      " |      extra_constraints : ndarray\n",
      " |          not tested yet\n",
      " |      combine_terms : None or list of strings\n",
      " |          Each string in this list is matched to the name of the terms or\n",
      " |          the name of the exogenous variables. All columns whose name\n",
      " |          includes that string are combined in one joint test.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      test_result : result instance\n",
      " |          The result instance contains `table` which is a pandas DataFrame\n",
      " |          with the test results: test statistic, degrees of freedom and\n",
      " |          pvalues.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> res_ols = ols(\"np.log(Days+1) ~ C(Duration, Sum)*C(Weight, Sum)\", data).fit()\n",
      " |      >>> res_ols.wald_test_terms()\n",
      " |      <class 'statsmodels.stats.contrast.WaldTestResults'>\n",
      " |                                                F                P>F  df constraint  df denom\n",
      " |      Intercept                        279.754525  2.37985521351e-22              1        51\n",
      " |      C(Duration, Sum)                   5.367071    0.0245738436636              1        51\n",
      " |      C(Weight, Sum)                    12.432445  3.99943118767e-05              2        51\n",
      " |      C(Duration, Sum):C(Weight, Sum)    0.176002      0.83912310946              2        51\n",
      " |      \n",
      " |      >>> res_poi = Poisson.from_formula(\"Days ~ C(Weight) * C(Duration)\",                                            data).fit(cov_type='HC0')\n",
      " |      >>> wt = res_poi.wald_test_terms(skip_single=False,                                          combine_terms=['Duration', 'Weight'])\n",
      " |      >>> print(wt)\n",
      " |                                  chi2             P>chi2  df constraint\n",
      " |      Intercept              15.695625  7.43960374424e-05              1\n",
      " |      C(Weight)              16.132616  0.000313940174705              2\n",
      " |      C(Duration)             1.009147     0.315107378931              1\n",
      " |      C(Weight):C(Duration)   0.216694     0.897315972824              2\n",
      " |      Duration               11.187849     0.010752286833              3\n",
      " |      Weight                 30.263368  4.32586407145e-06              4\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  load(fname) from builtins.type\n",
      " |      load a pickle, (class method)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : string or filehandle\n",
      " |          fname can be a string to a file path or filename, or a filehandle.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      unpickled instance\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  use_t = False\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Results:\n",
      " |  \n",
      " |  initialize(self, model, params, **kwd)\n",
      " |  \n",
      " |  predict(self, exog=None, transform=True, *args, **kwargs)\n",
      " |      Call self.model.predict with self.params as the first argument.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      exog : array-like, optional\n",
      " |          The values for which you want to predict. see Notes below.\n",
      " |      transform : bool, optional\n",
      " |          If the model was fit via a formula, do you want to pass\n",
      " |          exog through the formula. Default is True. E.g., if you fit\n",
      " |          a model y ~ log(x1) + log(x2), and transform is True, then\n",
      " |          you can pass a data structure that contains x1 and x2 in\n",
      " |          their original form. Otherwise, you'd need to log the data\n",
      " |          first.\n",
      " |      args, kwargs :\n",
      " |          Some models can take additional arguments or keywords, see the\n",
      " |          predict method of the model for the details.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prediction : ndarray, pandas.Series or pandas.DataFrame\n",
      " |          See self.model.predict\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The types of exog that are supported depends on whether a formula\n",
      " |      was used in the specification of the model.\n",
      " |      \n",
      " |      If a formula was used, then exog is processed in the same way as\n",
      " |      the original data. This transformation needs to have key access to the\n",
      " |      same variable names, and can be a pandas DataFrame or a dict like\n",
      " |      object.\n",
      " |      \n",
      " |      If no formula was used, then the provided exog needs to have the\n",
      " |      same number of columns as the original exog in the model. No\n",
      " |      transformation of the data is performed except converting it to\n",
      " |      a numpy array.\n",
      " |      \n",
      " |      Row indices as in pandas data frames are supported, and added to the\n",
      " |      returned prediction.\n",
      " |  \n",
      " |  summary(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from Results:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model.LikelihoodModelResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.regression.linear_model import RegressionResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class RegressionResults in module statsmodels.regression.linear_model:\n",
      "\n",
      "class RegressionResults(statsmodels.base.model.LikelihoodModelResults)\n",
      " |  RegressionResults(model, params, normalized_cov_params=None, scale=1.0, cov_type='nonrobust', cov_kwds=None, use_t=None, **kwargs)\n",
      " |  \n",
      " |  This class summarizes the fit of a linear regression model.\n",
      " |  \n",
      " |  It handles the output of contrasts, estimates of covariance, etc.\n",
      " |  \n",
      " |  Returns\n",
      " |  -------\n",
      " |  **Attributes**\n",
      " |  \n",
      " |  aic\n",
      " |      Akaike's information criteria. For a model with a constant\n",
      " |      :math:`-2llf + 2(df\\_model + 1)`. For a model without a constant\n",
      " |      :math:`-2llf + 2(df\\_model)`.\n",
      " |  bic\n",
      " |      Bayes' information criteria. For a model with a constant\n",
      " |      :math:`-2llf + \\log(n)(df\\_model+1)`. For a model without a constant\n",
      " |      :math:`-2llf + \\log(n)(df\\_model)`\n",
      " |  bse\n",
      " |      The standard errors of the parameter estimates.\n",
      " |  pinv_wexog\n",
      " |      See specific model class docstring\n",
      " |  centered_tss\n",
      " |      The total (weighted) sum of squares centered about the mean.\n",
      " |  cov_HC0\n",
      " |      Heteroscedasticity robust covariance matrix. See HC0_se below.\n",
      " |  cov_HC1\n",
      " |      Heteroscedasticity robust covariance matrix. See HC1_se below.\n",
      " |  cov_HC2\n",
      " |      Heteroscedasticity robust covariance matrix. See HC2_se below.\n",
      " |  cov_HC3\n",
      " |      Heteroscedasticity robust covariance matrix. See HC3_se below.\n",
      " |  cov_type\n",
      " |      Parameter covariance estimator used for standard errors and t-stats\n",
      " |  df_model\n",
      " |      Model degrees of freedom. The number of regressors `p`. Does not\n",
      " |      include the constant if one is present\n",
      " |  df_resid\n",
      " |      Residual degrees of freedom. `n - p - 1`, if a constant is present.\n",
      " |      `n - p` if a constant is not included.\n",
      " |  ess\n",
      " |      Explained sum of squares.  If a constant is present, the centered\n",
      " |      total sum of squares minus the sum of squared residuals. If there is\n",
      " |      no constant, the uncentered total sum of squares is used.\n",
      " |  fvalue\n",
      " |      F-statistic of the fully specified model.  Calculated as the mean\n",
      " |      squared error of the model divided by the mean squared error of the\n",
      " |      residuals.\n",
      " |  f_pvalue\n",
      " |      p-value of the F-statistic\n",
      " |  fittedvalues\n",
      " |      The predicted values for the original (unwhitened) design.\n",
      " |  het_scale\n",
      " |      adjusted squared residuals for heteroscedasticity robust standard\n",
      " |      errors. Is only available after `HC#_se` or `cov_HC#` is called.\n",
      " |      See HC#_se for more information.\n",
      " |  history\n",
      " |      Estimation history for iterative estimators\n",
      " |  HC0_se\n",
      " |      White's (1980) heteroskedasticity robust standard errors.\n",
      " |      Defined as sqrt(diag(X.T X)^(-1)X.T diag(e_i^(2)) X(X.T X)^(-1)\n",
      " |      where e_i = resid[i]\n",
      " |      HC0_se is a cached property.\n",
      " |      When HC0_se or cov_HC0 is called the RegressionResults instance will\n",
      " |      then have another attribute `het_scale`, which is in this case is just\n",
      " |      resid**2.\n",
      " |  HC1_se\n",
      " |      MacKinnon and White's (1985) alternative heteroskedasticity robust\n",
      " |      standard errors.\n",
      " |      Defined as sqrt(diag(n/(n-p)*HC_0)\n",
      " |      HC1_see is a cached property.\n",
      " |      When HC1_se or cov_HC1 is called the RegressionResults instance will\n",
      " |      then have another attribute `het_scale`, which is in this case is\n",
      " |      n/(n-p)*resid**2.\n",
      " |  HC2_se\n",
      " |      MacKinnon and White's (1985) alternative heteroskedasticity robust\n",
      " |      standard errors.\n",
      " |      Defined as (X.T X)^(-1)X.T diag(e_i^(2)/(1-h_ii)) X(X.T X)^(-1)\n",
      " |      where h_ii = x_i(X.T X)^(-1)x_i.T\n",
      " |      HC2_see is a cached property.\n",
      " |      When HC2_se or cov_HC2 is called the RegressionResults instance will\n",
      " |      then have another attribute `het_scale`, which is in this case is\n",
      " |      resid^(2)/(1-h_ii).\n",
      " |  HC3_se\n",
      " |      MacKinnon and White's (1985) alternative heteroskedasticity robust\n",
      " |      standard errors.\n",
      " |      Defined as (X.T X)^(-1)X.T diag(e_i^(2)/(1-h_ii)^(2)) X(X.T X)^(-1)\n",
      " |      where h_ii = x_i(X.T X)^(-1)x_i.T\n",
      " |      HC3_see is a cached property.\n",
      " |      When HC3_se or cov_HC3 is called the RegressionResults instance will\n",
      " |      then have another attribute `het_scale`, which is in this case is\n",
      " |      resid^(2)/(1-h_ii)^(2).\n",
      " |  model\n",
      " |      A pointer to the model instance that called fit() or results.\n",
      " |  mse_model\n",
      " |      Mean squared error the model. This is the explained sum of\n",
      " |      squares divided by the model degrees of freedom.\n",
      " |  mse_resid\n",
      " |      Mean squared error of the residuals.  The sum of squared\n",
      " |      residuals divided by the residual degrees of freedom.\n",
      " |  mse_total\n",
      " |      Total mean squared error.  Defined as the uncentered total sum\n",
      " |      of squares divided by n the number of observations.\n",
      " |  nobs\n",
      " |      Number of observations n.\n",
      " |  normalized_cov_params\n",
      " |      See specific model class docstring\n",
      " |  params\n",
      " |      The linear coefficients that minimize the least squares\n",
      " |      criterion.  This is usually called Beta for the classical\n",
      " |      linear model.\n",
      " |  pvalues\n",
      " |      The two-tailed p values for the t-stats of the params.\n",
      " |  resid\n",
      " |      The residuals of the model.\n",
      " |  resid_pearson\n",
      " |      `wresid` normalized to have unit variance.\n",
      " |  rsquared\n",
      " |      R-squared of a model with an intercept.  This is defined here\n",
      " |      as 1 - `ssr`/`centered_tss` if the constant is included in the\n",
      " |      model and 1 - `ssr`/`uncentered_tss` if the constant is\n",
      " |      omitted.\n",
      " |  rsquared_adj\n",
      " |      Adjusted R-squared.  This is defined here as 1 -\n",
      " |      (`nobs`-1)/`df_resid` * (1-`rsquared`) if a constant is\n",
      " |      included and 1 - `nobs`/`df_resid` * (1-`rsquared`) if no\n",
      " |      constant is included.\n",
      " |  scale\n",
      " |      A scale factor for the covariance matrix.  Default value is\n",
      " |      ssr/(n-p).  Note that the square root of `scale` is often\n",
      " |      called the standard error of the regression.\n",
      " |  ssr\n",
      " |      Sum of squared (whitened) residuals.\n",
      " |  uncentered_tss\n",
      " |      Uncentered sum of squares.  Sum of the squared values of the\n",
      " |      (whitened) endogenous response variable.\n",
      " |  wresid\n",
      " |      The residuals of the transformed/whitened regressand and\n",
      " |      regressor(s)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      RegressionResults\n",
      " |      statsmodels.base.model.LikelihoodModelResults\n",
      " |      statsmodels.base.model.Results\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  HC0_se(self)\n",
      " |      See statsmodels.RegressionResults\n",
      " |  \n",
      " |  HC1_se(self)\n",
      " |      See statsmodels.RegressionResults\n",
      " |  \n",
      " |  HC2_se(self)\n",
      " |      See statsmodels.RegressionResults\n",
      " |  \n",
      " |  HC3_se(self)\n",
      " |      See statsmodels.RegressionResults\n",
      " |  \n",
      " |  __init__(self, model, params, normalized_cov_params=None, scale=1.0, cov_type='nonrobust', cov_kwds=None, use_t=None, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  aic(self)\n",
      " |  \n",
      " |  bic(self)\n",
      " |  \n",
      " |  bse(self)\n",
      " |  \n",
      " |  centered_tss(self)\n",
      " |  \n",
      " |  compare_f_test(self, restricted)\n",
      " |      use F test to test whether restricted model is correct\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      restricted : Result instance\n",
      " |          The restricted model is assumed to be nested in the\n",
      " |          current model. The result instance of the restricted model\n",
      " |          is required to have two attributes, residual sum of\n",
      " |          squares, `ssr`, residual degrees of freedom, `df_resid`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      f_value : float\n",
      " |          test statistic, F distributed\n",
      " |      p_value : float\n",
      " |          p-value of the test statistic\n",
      " |      df_diff : int\n",
      " |          degrees of freedom of the restriction, i.e. difference in\n",
      " |          df between models\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See mailing list discussion October 17,\n",
      " |      \n",
      " |      This test compares the residual sum of squares of the two\n",
      " |      models.  This is not a valid test, if there is unspecified\n",
      " |      heteroscedasticity or correlation. This method will issue a\n",
      " |      warning if this is detected but still return the results under\n",
      " |      the assumption of homoscedasticity and no autocorrelation\n",
      " |      (sphericity).\n",
      " |  \n",
      " |  compare_lm_test(self, restricted, demean=True, use_lr=False)\n",
      " |      Use Lagrange Multiplier test to test whether restricted model is correct\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      restricted : Result instance\n",
      " |          The restricted model is assumed to be nested in the\n",
      " |          current model. The result instance of the restricted model\n",
      " |          is required to have two attributes, residual sum of\n",
      " |          squares, `ssr`, residual degrees of freedom, `df_resid`.\n",
      " |      \n",
      " |      demean : bool\n",
      " |          Flag indicating whether the demean the scores based on the\n",
      " |          residuals from the restricted model.  If True, the\n",
      " |          covariance of the scores are used and the LM test is\n",
      " |          identical to the large sample version of the LR test.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      lm_value : float\n",
      " |          test statistic, chi2 distributed\n",
      " |      p_value : float\n",
      " |          p-value of the test statistic\n",
      " |      df_diff : int\n",
      " |          degrees of freedom of the restriction, i.e. difference in df\n",
      " |          between models\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      TODO: explain LM text\n",
      " |  \n",
      " |  compare_lr_test(self, restricted, large_sample=False)\n",
      " |      Likelihood ratio test to test whether restricted model is correct\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      restricted : Result instance\n",
      " |          The restricted model is assumed to be nested in the current model.\n",
      " |          The result instance of the restricted model is required to have two\n",
      " |          attributes, residual sum of squares, `ssr`, residual degrees of\n",
      " |          freedom, `df_resid`.\n",
      " |      \n",
      " |      large_sample : bool\n",
      " |          Flag indicating whether to use a heteroskedasticity robust version\n",
      " |          of the LR test, which is a modified LM test.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      lr_stat : float\n",
      " |          likelihood ratio, chisquare distributed with df_diff degrees of\n",
      " |          freedom\n",
      " |      p_value : float\n",
      " |          p-value of the test statistic\n",
      " |      df_diff : int\n",
      " |          degrees of freedom of the restriction, i.e. difference in df\n",
      " |          between models\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      The exact likelihood ratio is valid for homoskedastic data,\n",
      " |      and is defined as\n",
      " |      \n",
      " |      .. math:: D=-2\\log\\left(\\frac{\\mathcal{L}_{null}}\n",
      " |         {\\mathcal{L}_{alternative}}\\right)\n",
      " |      \n",
      " |      where :math:`\\mathcal{L}` is the likelihood of the\n",
      " |      model. With :math:`D` distributed as chisquare with df equal\n",
      " |      to difference in number of parameters or equivalently\n",
      " |      difference in residual degrees of freedom.\n",
      " |      \n",
      " |      The large sample version of the likelihood ratio is defined as\n",
      " |      \n",
      " |      .. math:: D=n s^{\\prime}S^{-1}s\n",
      " |      \n",
      " |      where :math:`s=n^{-1}\\sum_{i=1}^{n} s_{i}`\n",
      " |      \n",
      " |      .. math:: s_{i} = x_{i,alternative} \\epsilon_{i,null}\n",
      " |      \n",
      " |      is the average score of the model evaluated using the\n",
      " |      residuals from null model and the regressors from the\n",
      " |      alternative model and :math:`S` is the covariance of the\n",
      " |      scores, :math:`s_{i}`.  The covariance of the scores is\n",
      " |      estimated using the same estimator as in the alternative\n",
      " |      model.\n",
      " |      \n",
      " |      This test compares the loglikelihood of the two models.  This\n",
      " |      may not be a valid test, if there is unspecified\n",
      " |      heteroscedasticity or correlation. This method will issue a\n",
      " |      warning if this is detected but still return the results\n",
      " |      without taking unspecified heteroscedasticity or correlation\n",
      " |      into account.\n",
      " |      \n",
      " |      This test compares the loglikelihood of the two models.  This\n",
      " |      may not be a valid test, if there is unspecified\n",
      " |      heteroscedasticity or correlation. This method will issue a\n",
      " |      warning if this is detected but still return the results\n",
      " |      without taking unspecified heteroscedasticity or correlation\n",
      " |      into account.\n",
      " |      \n",
      " |      is the average score of the model evaluated using the\n",
      " |      residuals from null model and the regressors from the\n",
      " |      alternative model and :math:`S` is the covariance of the\n",
      " |      scores, :math:`s_{i}`.  The covariance of the scores is\n",
      " |      estimated using the same estimator as in the alternative\n",
      " |      model.\n",
      " |      \n",
      " |      TODO: put into separate function, needs tests\n",
      " |  \n",
      " |  condition_number(self)\n",
      " |      Return condition number of exogenous matrix.\n",
      " |      \n",
      " |      Calculated as ratio of largest to smallest eigenvalue.\n",
      " |  \n",
      " |  conf_int(self, alpha=0.05, cols=None)\n",
      " |      Returns the confidence interval of the fitted parameters.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      alpha : float, optional\n",
      " |          The `alpha` level for the confidence interval.\n",
      " |          ie., The default `alpha` = .05 returns a 95% confidence interval.\n",
      " |      cols : array-like, optional\n",
      " |          `cols` specifies which confidence intervals to return\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The confidence interval is based on Student's t-distribution.\n",
      " |  \n",
      " |  cov_HC0(self)\n",
      " |      See statsmodels.RegressionResults\n",
      " |  \n",
      " |  cov_HC1(self)\n",
      " |      See statsmodels.RegressionResults\n",
      " |  \n",
      " |  cov_HC2(self)\n",
      " |      See statsmodels.RegressionResults\n",
      " |  \n",
      " |  cov_HC3(self)\n",
      " |      See statsmodels.RegressionResults\n",
      " |  \n",
      " |  eigenvals(self)\n",
      " |      Return eigenvalues sorted in decreasing order.\n",
      " |  \n",
      " |  ess(self)\n",
      " |  \n",
      " |  f_pvalue(self)\n",
      " |  \n",
      " |  fittedvalues(self)\n",
      " |  \n",
      " |  fvalue(self)\n",
      " |  \n",
      " |  get_prediction(self, exog=None, transform=True, weights=None, row_labels=None, **kwds)\n",
      " |      compute prediction results\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      exog : array-like, optional\n",
      " |          The values for which you want to predict.\n",
      " |      transform : bool, optional\n",
      " |          If the model was fit via a formula, do you want to pass\n",
      " |          exog through the formula. Default is True. E.g., if you fit\n",
      " |          a model y ~ log(x1) + log(x2), and transform is True, then\n",
      " |          you can pass a data structure that contains x1 and x2 in\n",
      " |          their original form. Otherwise, you'd need to log the data\n",
      " |          first.\n",
      " |      weights : array_like, optional\n",
      " |          Weights interpreted as in WLS, used for the variance of the predicted\n",
      " |          residual.\n",
      " |      args, kwargs :\n",
      " |          Some models can take additional arguments or keywords, see the\n",
      " |          predict method of the model for the details.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prediction_results : linear_model.PredictionResults\n",
      " |          The prediction results instance contains prediction and prediction\n",
      " |          variance and can on demand calculate confidence intervals and summary\n",
      " |          tables for the prediction of the mean and of new observations.\n",
      " |  \n",
      " |  get_robustcov_results(self, cov_type='HC1', use_t=None, **kwds)\n",
      " |      create new results instance with robust covariance as default\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cov_type : string\n",
      " |          the type of robust sandwich estimator to use. see Notes below\n",
      " |      use_t : bool\n",
      " |          If true, then the t distribution is used for inference.\n",
      " |          If false, then the normal distribution is used.\n",
      " |          If `use_t` is None, then an appropriate default is used, which is\n",
      " |          `true` if the cov_type is nonrobust, and `false` in all other\n",
      " |          cases.\n",
      " |      kwds : depends on cov_type\n",
      " |          Required or optional arguments for robust covariance calculation.\n",
      " |          see Notes below\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      results : results instance\n",
      " |          This method creates a new results instance with the\n",
      " |          requested robust covariance as the default covariance of\n",
      " |          the parameters.  Inferential statistics like p-values and\n",
      " |          hypothesis tests will be based on this covariance matrix.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The following covariance types and required or optional arguments are\n",
      " |      currently available:\n",
      " |      \n",
      " |      - 'fixed scale' and optional keyword argument 'scale' which uses\n",
      " |          a predefined scale estimate with default equal to one.\n",
      " |      - 'HC0', 'HC1', 'HC2', 'HC3' and no keyword arguments:\n",
      " |          heteroscedasticity robust covariance\n",
      " |      - 'HAC' and keywords\n",
      " |      \n",
      " |          - `maxlag` integer (required) : number of lags to use\n",
      " |          - `kernel` callable or str (optional) : kernel\n",
      " |                currently available kernels are ['bartlett', 'uniform'],\n",
      " |                default is Bartlett\n",
      " |          - `use_correction` bool (optional) : If true, use small sample\n",
      " |                correction\n",
      " |      \n",
      " |      - 'cluster' and required keyword `groups`, integer group indicator\n",
      " |      \n",
      " |          - `groups` array_like, integer (required) :\n",
      " |                index of clusters or groups\n",
      " |          - `use_correction` bool (optional) :\n",
      " |                If True the sandwich covariance is calculated with a small\n",
      " |                sample correction.\n",
      " |                If False the sandwich covariance is calculated without\n",
      " |                small sample correction.\n",
      " |          - `df_correction` bool (optional)\n",
      " |                If True (default), then the degrees of freedom for the\n",
      " |                inferential statistics and hypothesis tests, such as\n",
      " |                pvalues, f_pvalue, conf_int, and t_test and f_test, are\n",
      " |                based on the number of groups minus one instead of the\n",
      " |                total number of observations minus the number of explanatory\n",
      " |                variables. `df_resid` of the results instance is adjusted.\n",
      " |                If False, then `df_resid` of the results instance is not\n",
      " |                adjusted.\n",
      " |      \n",
      " |      - 'hac-groupsum' Driscoll and Kraay, heteroscedasticity and\n",
      " |          autocorrelation robust standard errors in panel data\n",
      " |          keywords\n",
      " |      \n",
      " |          - `time` array_like (required) : index of time periods\n",
      " |          - `maxlag` integer (required) : number of lags to use\n",
      " |          - `kernel` callable or str (optional) : kernel\n",
      " |                currently available kernels are ['bartlett', 'uniform'],\n",
      " |                default is Bartlett\n",
      " |          - `use_correction` False or string in ['hac', 'cluster'] (optional) :\n",
      " |                If False the the sandwich covariance is calulated without\n",
      " |                small sample correction.\n",
      " |                If `use_correction = 'cluster'` (default), then the same\n",
      " |                small sample correction as in the case of 'covtype='cluster''\n",
      " |                is used.\n",
      " |          - `df_correction` bool (optional)\n",
      " |                adjustment to df_resid, see cov_type 'cluster' above\n",
      " |                # TODO: we need more options here\n",
      " |      \n",
      " |      - 'hac-panel' heteroscedasticity and autocorrelation robust standard\n",
      " |          errors in panel data.\n",
      " |          The data needs to be sorted in this case, the time series\n",
      " |          for each panel unit or cluster need to be stacked. The\n",
      " |          membership to a timeseries of an individual or group can\n",
      " |          be either specified by group indicators or by increasing\n",
      " |          time periods.\n",
      " |      \n",
      " |          keywords\n",
      " |      \n",
      " |          - either `groups` or `time` : array_like (required)\n",
      " |            `groups` : indicator for groups\n",
      " |            `time` : index of time periods\n",
      " |          - `maxlag` integer (required) : number of lags to use\n",
      " |          - `kernel` callable or str (optional) : kernel\n",
      " |                currently available kernels are ['bartlett', 'uniform'],\n",
      " |                default is Bartlett\n",
      " |          - `use_correction` False or string in ['hac', 'cluster'] (optional) :\n",
      " |                If False the sandwich covariance is calculated without\n",
      " |                small sample correction.\n",
      " |          - `df_correction` bool (optional)\n",
      " |                adjustment to df_resid, see cov_type 'cluster' above\n",
      " |                # TODO: we need more options here\n",
      " |      \n",
      " |      Reminder:\n",
      " |      `use_correction` in \"hac-groupsum\" and \"hac-panel\" is not bool,\n",
      " |      needs to be in [False, 'hac', 'cluster']\n",
      " |      \n",
      " |      TODO: Currently there is no check for extra or misspelled keywords,\n",
      " |      except in the case of cov_type `HCx`\n",
      " |  \n",
      " |  mse_model(self)\n",
      " |  \n",
      " |  mse_resid(self)\n",
      " |  \n",
      " |  mse_total(self)\n",
      " |  \n",
      " |  nobs(self)\n",
      " |  \n",
      " |  resid(self)\n",
      " |  \n",
      " |  resid_pearson(self)\n",
      " |      Residuals, normalized to have unit variance.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      An array wresid standardized by the sqrt if scale\n",
      " |  \n",
      " |  rsquared(self)\n",
      " |  \n",
      " |  rsquared_adj(self)\n",
      " |  \n",
      " |  scale(self)\n",
      " |      # TODO: fix writable example\n",
      " |  \n",
      " |  ssr(self)\n",
      " |  \n",
      " |  summary(self, yname=None, xname=None, title=None, alpha=0.05)\n",
      " |      Summarize the Regression Results\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      yname : string, optional\n",
      " |          Default is `y`\n",
      " |      xname : list of strings, optional\n",
      " |          Default is `var_##` for ## in p the number of regressors\n",
      " |      title : string, optional\n",
      " |          Title for the top table. If not None, then this replaces the\n",
      " |          default title\n",
      " |      alpha : float\n",
      " |          significance level for the confidence intervals\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      smry : Summary instance\n",
      " |          this holds the summary tables and text, which can be printed or\n",
      " |          converted to various output formats.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      statsmodels.iolib.summary.Summary : class to hold summary\n",
      " |          results\n",
      " |  \n",
      " |  summary2(self, yname=None, xname=None, title=None, alpha=0.05, float_format='%.4f')\n",
      " |      Experimental summary function to summarize the regression results\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      xname : List of strings of length equal to the number of parameters\n",
      " |          Names of the independent variables (optional)\n",
      " |      yname : string\n",
      " |          Name of the dependent variable (optional)\n",
      " |      title : string, optional\n",
      " |          Title for the top table. If not None, then this replaces the\n",
      " |          default title\n",
      " |      alpha : float\n",
      " |          significance level for the confidence intervals\n",
      " |      float_format: string\n",
      " |          print format for floats in parameters summary\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      smry : Summary instance\n",
      " |          this holds the summary tables and text, which can be printed or\n",
      " |          converted to various output formats.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      statsmodels.iolib.summary.Summary : class to hold summary\n",
      " |          results\n",
      " |  \n",
      " |  uncentered_tss(self)\n",
      " |  \n",
      " |  wresid(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from statsmodels.base.model.LikelihoodModelResults:\n",
      " |  \n",
      " |  cov_params(self, r_matrix=None, column=None, scale=None, cov_p=None, other=None)\n",
      " |      Returns the variance/covariance matrix.\n",
      " |      \n",
      " |      The variance/covariance matrix can be of a linear contrast\n",
      " |      of the estimates of params or all params multiplied by scale which\n",
      " |      will usually be an estimate of sigma^2.  Scale is assumed to be\n",
      " |      a scalar.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      r_matrix : array-like\n",
      " |          Can be 1d, or 2d.  Can be used alone or with other.\n",
      " |      column :  array-like, optional\n",
      " |          Must be used on its own.  Can be 0d or 1d see below.\n",
      " |      scale : float, optional\n",
      " |          Can be specified or not.  Default is None, which means that\n",
      " |          the scale argument is taken from the model.\n",
      " |      other : array-like, optional\n",
      " |          Can be used when r_matrix is specified.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      cov : ndarray\n",
      " |          covariance matrix of the parameter estimates or of linear\n",
      " |          combination of parameter estimates. See Notes.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      (The below are assumed to be in matrix notation.)\n",
      " |      \n",
      " |      If no argument is specified returns the covariance matrix of a model\n",
      " |      ``(scale)*(X.T X)^(-1)``\n",
      " |      \n",
      " |      If contrast is specified it pre and post-multiplies as follows\n",
      " |      ``(scale) * r_matrix (X.T X)^(-1) r_matrix.T``\n",
      " |      \n",
      " |      If contrast and other are specified returns\n",
      " |      ``(scale) * r_matrix (X.T X)^(-1) other.T``\n",
      " |      \n",
      " |      If column is specified returns\n",
      " |      ``(scale) * (X.T X)^(-1)[column,column]`` if column is 0d\n",
      " |      \n",
      " |      OR\n",
      " |      \n",
      " |      ``(scale) * (X.T X)^(-1)[column][:,column]`` if column is 1d\n",
      " |  \n",
      " |  f_test(self, r_matrix, cov_p=None, scale=1.0, invcov=None)\n",
      " |      Compute the F-test for a joint linear hypothesis.\n",
      " |      \n",
      " |      This is a special case of `wald_test` that always uses the F\n",
      " |      distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      r_matrix : array-like, str, or tuple\n",
      " |          - array : An r x k array where r is the number of restrictions to\n",
      " |            test and k is the number of regressors. It is assumed\n",
      " |            that the linear combination is equal to zero.\n",
      " |          - str : The full hypotheses to test can be given as a string.\n",
      " |            See the examples.\n",
      " |          - tuple : A tuple of arrays in the form (R, q), ``q`` can be\n",
      " |            either a scalar or a length k row vector.\n",
      " |      cov_p : array-like, optional\n",
      " |          An alternative estimate for the parameter covariance matrix.\n",
      " |          If None is given, self.normalized_cov_params is used.\n",
      " |      scale : float, optional\n",
      " |          Default is 1.0 for no scaling.\n",
      " |      invcov : array-like, optional\n",
      " |          A q x q array to specify an inverse covariance matrix based on a\n",
      " |          restrictions matrix.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      res : ContrastResults instance\n",
      " |          The results for the test are attributes of this results instance.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import numpy as np\n",
      " |      >>> import statsmodels.api as sm\n",
      " |      >>> data = sm.datasets.longley.load()\n",
      " |      >>> data.exog = sm.add_constant(data.exog)\n",
      " |      >>> results = sm.OLS(data.endog, data.exog).fit()\n",
      " |      >>> A = np.identity(len(results.params))\n",
      " |      >>> A = A[1:,:]\n",
      " |      \n",
      " |      This tests that each coefficient is jointly statistically\n",
      " |      significantly different from zero.\n",
      " |      \n",
      " |      >>> print(results.f_test(A))\n",
      " |      <F test: F=array([[ 330.28533923]]), p=4.984030528700946e-10, df_denom=9, df_num=6>\n",
      " |      \n",
      " |      Compare this to\n",
      " |      \n",
      " |      >>> results.fvalue\n",
      " |      330.2853392346658\n",
      " |      >>> results.f_pvalue\n",
      " |      4.98403096572e-10\n",
      " |      \n",
      " |      >>> B = np.array(([0,0,1,-1,0,0,0],[0,0,0,0,0,1,-1]))\n",
      " |      \n",
      " |      This tests that the coefficient on the 2nd and 3rd regressors are\n",
      " |      equal and jointly that the coefficient on the 5th and 6th regressors\n",
      " |      are equal.\n",
      " |      \n",
      " |      >>> print(results.f_test(B))\n",
      " |      <F test: F=array([[ 9.74046187]]), p=0.005605288531708235, df_denom=9, df_num=2>\n",
      " |      \n",
      " |      Alternatively, you can specify the hypothesis tests using a string\n",
      " |      \n",
      " |      >>> from statsmodels.datasets import longley\n",
      " |      >>> from statsmodels.formula.api import ols\n",
      " |      >>> dta = longley.load_pandas().data\n",
      " |      >>> formula = 'TOTEMP ~ GNPDEFL + GNP + UNEMP + ARMED + POP + YEAR'\n",
      " |      >>> results = ols(formula, dta).fit()\n",
      " |      >>> hypotheses = '(GNPDEFL = GNP), (UNEMP = 2), (YEAR/1829 = 1)'\n",
      " |      >>> f_test = results.f_test(hypotheses)\n",
      " |      >>> print(f_test)\n",
      " |      <F test: F=array([[ 144.17976065]]), p=6.322026217355609e-08, df_denom=9, df_num=3>\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      statsmodels.stats.contrast.ContrastResults\n",
      " |      wald_test\n",
      " |      t_test\n",
      " |      patsy.DesignInfo.linear_constraint\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The matrix `r_matrix` is assumed to be non-singular. More precisely,\n",
      " |      \n",
      " |      r_matrix (pX pX.T) r_matrix.T\n",
      " |      \n",
      " |      is assumed invertible. Here, pX is the generalized inverse of the\n",
      " |      design matrix of the model. There can be problems in non-OLS models\n",
      " |      where the rank of the covariance of the noise is not full.\n",
      " |  \n",
      " |  llf(self)\n",
      " |  \n",
      " |  normalized_cov_params(self)\n",
      " |  \n",
      " |  pvalues(self)\n",
      " |  \n",
      " |  remove_data(self)\n",
      " |      remove data arrays, all nobs arrays from result and model\n",
      " |      \n",
      " |      This reduces the size of the instance, so it can be pickled with less\n",
      " |      memory. Currently tested for use with predict from an unpickled\n",
      " |      results and model instance.\n",
      " |      \n",
      " |      .. warning:: Since data and some intermediate results have been removed\n",
      " |         calculating new statistics that require them will raise exceptions.\n",
      " |         The exception will occur the first time an attribute is accessed\n",
      " |         that has been set to None.\n",
      " |      \n",
      " |      Not fully tested for time series models, tsa, and might delete too much\n",
      " |      for prediction or not all that would be possible.\n",
      " |      \n",
      " |      The lists of arrays to delete are maintained as attributes of\n",
      " |      the result and model instance, except for cached values. These\n",
      " |      lists could be changed before calling remove_data.\n",
      " |      \n",
      " |      The attributes to remove are named in:\n",
      " |      \n",
      " |      model._data_attr : arrays attached to both the model instance\n",
      " |          and the results instance with the same attribute name.\n",
      " |      \n",
      " |      result.data_in_cache : arrays that may exist as values in\n",
      " |          result._cache (TODO : should privatize name)\n",
      " |      \n",
      " |      result._data_attr_model : arrays attached to the model\n",
      " |          instance but not to the results instance\n",
      " |  \n",
      " |  save(self, fname, remove_data=False)\n",
      " |      save a pickle of this instance\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : string or filehandle\n",
      " |          fname can be a string to a file path or filename, or a filehandle.\n",
      " |      remove_data : bool\n",
      " |          If False (default), then the instance is pickled without changes.\n",
      " |          If True, then all arrays with length nobs are set to None before\n",
      " |          pickling. See the remove_data method.\n",
      " |          In some cases not all arrays will be set to None.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If remove_data is true and the model result does not implement a\n",
      " |      remove_data method then this will raise an exception.\n",
      " |  \n",
      " |  t_test(self, r_matrix, cov_p=None, scale=None, use_t=None)\n",
      " |      Compute a t-test for a each linear hypothesis of the form Rb = q\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      r_matrix : array-like, str, tuple\n",
      " |          - array : If an array is given, a p x k 2d array or length k 1d\n",
      " |            array specifying the linear restrictions. It is assumed\n",
      " |            that the linear combination is equal to zero.\n",
      " |          - str : The full hypotheses to test can be given as a string.\n",
      " |            See the examples.\n",
      " |          - tuple : A tuple of arrays in the form (R, q). If q is given,\n",
      " |            can be either a scalar or a length p row vector.\n",
      " |      cov_p : array-like, optional\n",
      " |          An alternative estimate for the parameter covariance matrix.\n",
      " |          If None is given, self.normalized_cov_params is used.\n",
      " |      scale : float, optional\n",
      " |          An optional `scale` to use.  Default is the scale specified\n",
      " |          by the model fit.\n",
      " |      use_t : bool, optional\n",
      " |          If use_t is None, then the default of the model is used.\n",
      " |          If use_t is True, then the p-values are based on the t\n",
      " |          distribution.\n",
      " |          If use_t is False, then the p-values are based on the normal\n",
      " |          distribution.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      res : ContrastResults instance\n",
      " |          The results for the test are attributes of this results instance.\n",
      " |          The available results have the same elements as the parameter table\n",
      " |          in `summary()`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import numpy as np\n",
      " |      >>> import statsmodels.api as sm\n",
      " |      >>> data = sm.datasets.longley.load()\n",
      " |      >>> data.exog = sm.add_constant(data.exog)\n",
      " |      >>> results = sm.OLS(data.endog, data.exog).fit()\n",
      " |      >>> r = np.zeros_like(results.params)\n",
      " |      >>> r[5:] = [1,-1]\n",
      " |      >>> print(r)\n",
      " |      [ 0.  0.  0.  0.  0.  1. -1.]\n",
      " |      \n",
      " |      r tests that the coefficients on the 5th and 6th independent\n",
      " |      variable are the same.\n",
      " |      \n",
      " |      >>> T_test = results.t_test(r)\n",
      " |      >>> print(T_test)\n",
      " |                                   Test for Constraints\n",
      " |      ==============================================================================\n",
      " |                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      " |      ------------------------------------------------------------------------------\n",
      " |      c0         -1829.2026    455.391     -4.017      0.003   -2859.368    -799.037\n",
      " |      ==============================================================================\n",
      " |      >>> T_test.effect\n",
      " |      -1829.2025687192481\n",
      " |      >>> T_test.sd\n",
      " |      455.39079425193762\n",
      " |      >>> T_test.tvalue\n",
      " |      -4.0167754636411717\n",
      " |      >>> T_test.pvalue\n",
      " |      0.0015163772380899498\n",
      " |      \n",
      " |      Alternatively, you can specify the hypothesis tests using a string\n",
      " |      \n",
      " |      >>> from statsmodels.formula.api import ols\n",
      " |      >>> dta = sm.datasets.longley.load_pandas().data\n",
      " |      >>> formula = 'TOTEMP ~ GNPDEFL + GNP + UNEMP + ARMED + POP + YEAR'\n",
      " |      >>> results = ols(formula, dta).fit()\n",
      " |      >>> hypotheses = 'GNPDEFL = GNP, UNEMP = 2, YEAR/1829 = 1'\n",
      " |      >>> t_test = results.t_test(hypotheses)\n",
      " |      >>> print(t_test)\n",
      " |                                   Test for Constraints\n",
      " |      ==============================================================================\n",
      " |                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      " |      ------------------------------------------------------------------------------\n",
      " |      c0            15.0977     84.937      0.178      0.863    -177.042     207.238\n",
      " |      c1            -2.0202      0.488     -8.231      0.000      -3.125      -0.915\n",
      " |      c2             1.0001      0.249      0.000      1.000       0.437       1.563\n",
      " |      ==============================================================================\n",
      " |      \n",
      " |      See Also\n",
      " |      ---------\n",
      " |      tvalues : individual t statistics\n",
      " |      f_test : for F tests\n",
      " |      patsy.DesignInfo.linear_constraint\n",
      " |  \n",
      " |  t_test_pairwise(self, term_name, method='hs', alpha=0.05, factor_labels=None)\n",
      " |      perform pairwise t_test with multiple testing corrected p-values\n",
      " |      \n",
      " |      This uses the formula design_info encoding contrast matrix and should\n",
      " |      work for all encodings of a main effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      result : result instance\n",
      " |          The results of an estimated model with a categorical main effect.\n",
      " |      term_name : str\n",
      " |          name of the term for which pairwise comparisons are computed.\n",
      " |          Term names for categorical effects are created by patsy and\n",
      " |          correspond to the main part of the exog names.\n",
      " |      method : str or list of strings\n",
      " |          multiple testing p-value correction, default is 'hs',\n",
      " |          see stats.multipletesting\n",
      " |      alpha : float\n",
      " |          significance level for multiple testing reject decision.\n",
      " |      factor_labels : None, list of str\n",
      " |          Labels for the factor levels used for pairwise labels. If not\n",
      " |          provided, then the labels from the formula design_info are used.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      results : instance of a simple Results class\n",
      " |          The results are stored as attributes, the main attributes are the\n",
      " |          following two. Other attributes are added for debugging purposes\n",
      " |          or as background information.\n",
      " |      \n",
      " |          - result_frame : pandas DataFrame with t_test results and multiple\n",
      " |            testing corrected p-values.\n",
      " |          - contrasts : matrix of constraints of the null hypothesis in the\n",
      " |            t_test.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Status: experimental. Currently only checked for treatment coding with\n",
      " |      and without specified reference level.\n",
      " |      \n",
      " |      Currently there are no multiple testing corrected confidence intervals\n",
      " |      available.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> res = ols(\"np.log(Days+1) ~ C(Weight) + C(Duration)\", data).fit()\n",
      " |      >>> pw = res.t_test_pairwise(\"C(Weight)\")\n",
      " |      >>> pw.result_frame\n",
      " |               coef   std err         t         P>|t|  Conf. Int. Low\n",
      " |      2-1  0.632315  0.230003  2.749157  8.028083e-03        0.171563\n",
      " |      3-1  1.302555  0.230003  5.663201  5.331513e-07        0.841803\n",
      " |      3-2  0.670240  0.230003  2.914044  5.119126e-03        0.209488\n",
      " |           Conf. Int. Upp.  pvalue-hs reject-hs\n",
      " |      2-1         1.093067   0.010212      True\n",
      " |      3-1         1.763307   0.000002      True\n",
      " |      3-2         1.130992   0.010212      True\n",
      " |  \n",
      " |  tvalues(self)\n",
      " |      Return the t-statistic for a given parameter estimate.\n",
      " |  \n",
      " |  wald_test(self, r_matrix, cov_p=None, scale=1.0, invcov=None, use_f=None)\n",
      " |      Compute a Wald-test for a joint linear hypothesis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      r_matrix : array-like, str, or tuple\n",
      " |          - array : An r x k array where r is the number of restrictions to\n",
      " |            test and k is the number of regressors. It is assumed that the\n",
      " |            linear combination is equal to zero.\n",
      " |          - str : The full hypotheses to test can be given as a string.\n",
      " |            See the examples.\n",
      " |          - tuple : A tuple of arrays in the form (R, q), ``q`` can be\n",
      " |            either a scalar or a length p row vector.\n",
      " |      cov_p : array-like, optional\n",
      " |          An alternative estimate for the parameter covariance matrix.\n",
      " |          If None is given, self.normalized_cov_params is used.\n",
      " |      scale : float, optional\n",
      " |          Default is 1.0 for no scaling.\n",
      " |      invcov : array-like, optional\n",
      " |          A q x q array to specify an inverse covariance matrix based on a\n",
      " |          restrictions matrix.\n",
      " |      use_f : bool\n",
      " |          If True, then the F-distribution is used. If False, then the\n",
      " |          asymptotic distribution, chisquare is used. If use_f is None, then\n",
      " |          the F distribution is used if the model specifies that use_t is True.\n",
      " |          The test statistic is proportionally adjusted for the distribution\n",
      " |          by the number of constraints in the hypothesis.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      res : ContrastResults instance\n",
      " |          The results for the test are attributes of this results instance.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      statsmodels.stats.contrast.ContrastResults\n",
      " |      f_test\n",
      " |      t_test\n",
      " |      patsy.DesignInfo.linear_constraint\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The matrix `r_matrix` is assumed to be non-singular. More precisely,\n",
      " |      \n",
      " |      r_matrix (pX pX.T) r_matrix.T\n",
      " |      \n",
      " |      is assumed invertible. Here, pX is the generalized inverse of the\n",
      " |      design matrix of the model. There can be problems in non-OLS models\n",
      " |      where the rank of the covariance of the noise is not full.\n",
      " |  \n",
      " |  wald_test_terms(self, skip_single=False, extra_constraints=None, combine_terms=None)\n",
      " |      Compute a sequence of Wald tests for terms over multiple columns\n",
      " |      \n",
      " |      This computes joined Wald tests for the hypothesis that all\n",
      " |      coefficients corresponding to a `term` are zero.\n",
      " |      \n",
      " |      `Terms` are defined by the underlying formula or by string matching.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skip_single : boolean\n",
      " |          If true, then terms that consist only of a single column and,\n",
      " |          therefore, refers only to a single parameter is skipped.\n",
      " |          If false, then all terms are included.\n",
      " |      extra_constraints : ndarray\n",
      " |          not tested yet\n",
      " |      combine_terms : None or list of strings\n",
      " |          Each string in this list is matched to the name of the terms or\n",
      " |          the name of the exogenous variables. All columns whose name\n",
      " |          includes that string are combined in one joint test.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      test_result : result instance\n",
      " |          The result instance contains `table` which is a pandas DataFrame\n",
      " |          with the test results: test statistic, degrees of freedom and\n",
      " |          pvalues.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> res_ols = ols(\"np.log(Days+1) ~ C(Duration, Sum)*C(Weight, Sum)\", data).fit()\n",
      " |      >>> res_ols.wald_test_terms()\n",
      " |      <class 'statsmodels.stats.contrast.WaldTestResults'>\n",
      " |                                                F                P>F  df constraint  df denom\n",
      " |      Intercept                        279.754525  2.37985521351e-22              1        51\n",
      " |      C(Duration, Sum)                   5.367071    0.0245738436636              1        51\n",
      " |      C(Weight, Sum)                    12.432445  3.99943118767e-05              2        51\n",
      " |      C(Duration, Sum):C(Weight, Sum)    0.176002      0.83912310946              2        51\n",
      " |      \n",
      " |      >>> res_poi = Poisson.from_formula(\"Days ~ C(Weight) * C(Duration)\",                                            data).fit(cov_type='HC0')\n",
      " |      >>> wt = res_poi.wald_test_terms(skip_single=False,                                          combine_terms=['Duration', 'Weight'])\n",
      " |      >>> print(wt)\n",
      " |                                  chi2             P>chi2  df constraint\n",
      " |      Intercept              15.695625  7.43960374424e-05              1\n",
      " |      C(Weight)              16.132616  0.000313940174705              2\n",
      " |      C(Duration)             1.009147     0.315107378931              1\n",
      " |      C(Weight):C(Duration)   0.216694     0.897315972824              2\n",
      " |      Duration               11.187849     0.010752286833              3\n",
      " |      Weight                 30.263368  4.32586407145e-06              4\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from statsmodels.base.model.LikelihoodModelResults:\n",
      " |  \n",
      " |  load(fname) from builtins.type\n",
      " |      load a pickle, (class method)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : string or filehandle\n",
      " |          fname can be a string to a file path or filename, or a filehandle.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      unpickled instance\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from statsmodels.base.model.LikelihoodModelResults:\n",
      " |  \n",
      " |  use_t = False\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from statsmodels.base.model.Results:\n",
      " |  \n",
      " |  initialize(self, model, params, **kwd)\n",
      " |  \n",
      " |  predict(self, exog=None, transform=True, *args, **kwargs)\n",
      " |      Call self.model.predict with self.params as the first argument.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      exog : array-like, optional\n",
      " |          The values for which you want to predict. see Notes below.\n",
      " |      transform : bool, optional\n",
      " |          If the model was fit via a formula, do you want to pass\n",
      " |          exog through the formula. Default is True. E.g., if you fit\n",
      " |          a model y ~ log(x1) + log(x2), and transform is True, then\n",
      " |          you can pass a data structure that contains x1 and x2 in\n",
      " |          their original form. Otherwise, you'd need to log the data\n",
      " |          first.\n",
      " |      args, kwargs :\n",
      " |          Some models can take additional arguments or keywords, see the\n",
      " |          predict method of the model for the details.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prediction : ndarray, pandas.Series or pandas.DataFrame\n",
      " |          See self.model.predict\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The types of exog that are supported depends on whether a formula\n",
      " |      was used in the specification of the model.\n",
      " |      \n",
      " |      If a formula was used, then exog is processed in the same way as\n",
      " |      the original data. This transformation needs to have key access to the\n",
      " |      same variable names, and can be a pandas DataFrame or a dict like\n",
      " |      object.\n",
      " |      \n",
      " |      If no formula was used, then the provided exog needs to have the\n",
      " |      same number of columns as the original exog in the model. No\n",
      " |      transformation of the data is performed except converting it to\n",
      " |      a numpy array.\n",
      " |      \n",
      " |      Row indices as in pandas data frames are supported, and added to the\n",
      " |      returned prediction.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from statsmodels.base.model.Results:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(RegressionResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.graphics.api import interaction_plot,\\\n",
    "abline_plot,qqplot\n",
    "from statsmodels.stats.api import anova_lm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    salary_table=pd.read_csv('salary.table')\n",
    "except:\n",
    "    url='http://stats191.stanford.edu/data/salary.table'\n",
    "    salary_table=pd.read_csv(url)\n",
    "    salary_table.to_csv('salary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             S\\tX\\tE\\tM\n",
      "0    13876 \\t1 \\t1 \\t1 \n",
      "1    11608 \\t1 \\t3 \\t0 \n",
      "2    18701 \\t1 \\t3 \\t1 \n",
      "3    11283 \\t1 \\t2 \\t0 \n",
      "4    11767 \\t1 \\t3 \\t0 \n",
      "5    20872 \\t2 \\t2 \\t1 \n",
      "6    11772 \\t2 \\t2 \\t0 \n",
      "7    10535 \\t2 \\t1 \\t0 \n",
      "8    12195 \\t2 \\t3 \\t0 \n",
      "9    12313 \\t3 \\t2 \\t0 \n",
      "10   14975 \\t3 \\t1 \\t1 \n",
      "11   21371 \\t3 \\t2 \\t1 \n",
      "12   19800 \\t3 \\t3 \\t1 \n",
      "13   11417 \\t4 \\t1 \\t0 \n",
      "14   20263 \\t4 \\t3 \\t1 \n",
      "15   13231 \\t4 \\t3 \\t0 \n",
      "16   12884 \\t4 \\t2 \\t0 \n",
      "17   13245 \\t5 \\t2 \\t0 \n",
      "18   13677 \\t5 \\t3 \\t0 \n",
      "19   15965 \\t5 \\t1 \\t1 \n",
      "20   12336 \\t6 \\t1 \\t0 \n",
      "21   21352 \\t6 \\t3 \\t1 \n",
      "22   13839 \\t6 \\t2 \\t0 \n",
      "23   22884 \\t6 \\t2 \\t1 \n",
      "24   16978 \\t7 \\t1 \\t1 \n",
      "25   14803 \\t8 \\t2 \\t0 \n",
      "26   17404 \\t8 \\t1 \\t1 \n",
      "27   22184 \\t8 \\t3 \\t1 \n",
      "28   13548 \\t8 \\t1 \\t0 \n",
      "29  14467 \\t10 \\t1 \\t0 \n",
      "30  15942 \\t10 \\t2 \\t0 \n",
      "31  23174 \\t10 \\t3 \\t1 \n",
      "32  23780 \\t10 \\t2 \\t1 \n",
      "33  25410 \\t11 \\t2 \\t1 \n",
      "34  14861 \\t11 \\t1 \\t0 \n",
      "35  16882 \\t12 \\t2 \\t0 \n",
      "36  24170 \\t12 \\t3 \\t1 \n",
      "37  15990 \\t13 \\t1 \\t0 \n",
      "38  26330 \\t13 \\t2 \\t1 \n",
      "39  17949 \\t14 \\t2 \\t0 \n",
      "40  25685 \\t15 \\t3 \\t1 \n",
      "41  27837 \\t16 \\t2 \\t1 \n",
      "42  18838 \\t16 \\t2 \\t0 \n",
      "43  17483 \\t16 \\t1 \\t0 \n",
      "44  19207 \\t17 \\t2 \\t0 \n",
      "45  19346 \\t20 \\t1 \\t0 \n"
     ]
    }
   ],
   "source": [
    "print(salary_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-39-b050ea860084>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-39-b050ea860084>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    salary_table={'count:'np.arange(45),'tx:'np.random.random(45),'te:'np.random.random(45),'tm'np.random.random(45)}\u001b[0m\n\u001b[1;37m                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "salary_table={'count:'np.arange(45),'tx:'np.random.random(45),'te:'np.random.random(45),'tm'np.random.random(45)}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'tE'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-7f0e32446626>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mE\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msalary_table\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5065\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5066\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5067\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5069\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'tE'"
     ]
    }
   ],
   "source": [
    "E=salary_table.tE\n",
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "PatsyError",
     "evalue": "model is missing required outcome variables",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPatsyError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-0cd1ba3ddcb1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mformula\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'S-C(E)+C(M)+X'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mols\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msalary_table\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msalary_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36mfrom_formula\u001b[1;34m(cls, formula, data, subset, drop_cols, *args, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         tmp = handle_formula_data(data, None, formula, depth=eval_env,\n\u001b[1;32m--> 155\u001b[1;33m                                   missing=missing)\n\u001b[0m\u001b[0;32m    156\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesign_info\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\formula\\formulatools.py\u001b[0m in \u001b[0;36mhandle_formula_data\u001b[1;34m(Y, X, formula, depth, missing)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_using_pandas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             result = dmatrices(formula, Y, depth, return_type='dataframe',\n\u001b[1;32m---> 65\u001b[1;33m                                NA_action=na_action)\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             result = dmatrices(formula, Y, depth, return_type='dataframe',\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\patsy\\highlevel.py\u001b[0m in \u001b[0;36mdmatrices\u001b[1;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[0;32m    310\u001b[0m                                       NA_action, return_type)\n\u001b[0;32m    311\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlhs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mPatsyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model is missing required outcome variables\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlhs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPatsyError\u001b[0m: model is missing required outcome variables"
     ]
    }
   ],
   "source": [
    "formula='S-C(E)+C(M)+X'\n",
    "lm=ols(salary_table,salary_table).fit()\n",
    "print(lm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-ea6bc4dfd093>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'lm' is not defined"
     ]
    }
   ],
   "source": [
    "lm.model.exog[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-e19d3acaac33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manova_lm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msalary_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\stats\\anova.py\u001b[0m in \u001b[0;36manova_lm\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0manova_single\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\stats\\anova.py\u001b[0m in \u001b[0;36manova_single\u001b[1;34m(model, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mrobust\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrobust\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m     \u001b[0mendog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m     \u001b[0mexog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[0mnobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5065\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5066\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5067\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5069\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "print(anova_lm(salary_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'Leastsquares'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-365508422dc9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLeastsquares\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'Leastsquares'"
     ]
    }
   ],
   "source": [
    "pr=[0,0,0,0,0,1,-1]\n",
    "pr.Leastsquares()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function anova_lm in module statsmodels.stats.anova:\n",
      "\n",
      "anova_lm(*args, **kwargs)\n",
      "    Anova table for one or more fitted linear models.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    args : fitted linear model results instance\n",
      "        One or more fitted linear models\n",
      "    scale : float\n",
      "        Estimate of variance, If None, will be estimated from the largest\n",
      "        model. Default is None.\n",
      "    test : str {\"F\", \"Chisq\", \"Cp\"} or None\n",
      "        Test statistics to provide. Default is \"F\".\n",
      "    typ : str or int {\"I\",\"II\",\"III\"} or {1,2,3}\n",
      "        The type of Anova test to perform. See notes.\n",
      "    robust : {None, \"hc0\", \"hc1\", \"hc2\", \"hc3\"}\n",
      "        Use heteroscedasticity-corrected coefficient covariance matrix.\n",
      "        If robust covariance is desired, it is recommended to use `hc3`.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    anova : DataFrame\n",
      "    A DataFrame containing.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Model statistics are given in the order of args. Models must have\n",
      "    been fit using the formula api.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    model_results.compare_f_test, model_results.compare_lm_test\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import statsmodels.api as sm\n",
      "    >>> from statsmodels.formula.api import ols\n",
      "    >>> moore = sm.datasets.get_rdataset(\"Moore\", \"car\", cache=True) # load\n",
      "    >>> data = moore.data\n",
      "    >>> data = data.rename(columns={\"partner.status\" :\n",
      "    ...                             \"partner_status\"}) # make name pythonic\n",
      "    >>> moore_lm = ols('conformity ~ C(fcategory, Sum)*C(partner_status, Sum)',\n",
      "    ...                 data=data).fit()\n",
      "    >>> table = sm.stats.anova_lm(moore_lm, typ=2) # Type 2 Anova DataFrame\n",
      "    >>> print(table)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(anova_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
